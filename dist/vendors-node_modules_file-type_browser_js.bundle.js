/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunkdiscord_bot"] = self["webpackChunkdiscord_bot"] || []).push([["vendors-node_modules_file-type_browser_js"],{

/***/ "./node_modules/ieee754/index.js":
/*!***************************************!*\
  !*** ./node_modules/ieee754/index.js ***!
  \***************************************/
/***/ ((__unused_webpack_module, exports) => {

eval("/*! ieee754. BSD-3-Clause License. Feross Aboukhadijeh <https://feross.org/opensource> */\nexports.read = function (buffer, offset, isLE, mLen, nBytes) {\n  var e, m\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var nBits = -7\n  var i = isLE ? (nBytes - 1) : 0\n  var d = isLE ? -1 : 1\n  var s = buffer[offset + i]\n\n  i += d\n\n  e = s & ((1 << (-nBits)) - 1)\n  s >>= (-nBits)\n  nBits += eLen\n  for (; nBits > 0; e = (e * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  m = e & ((1 << (-nBits)) - 1)\n  e >>= (-nBits)\n  nBits += mLen\n  for (; nBits > 0; m = (m * 256) + buffer[offset + i], i += d, nBits -= 8) {}\n\n  if (e === 0) {\n    e = 1 - eBias\n  } else if (e === eMax) {\n    return m ? NaN : ((s ? -1 : 1) * Infinity)\n  } else {\n    m = m + Math.pow(2, mLen)\n    e = e - eBias\n  }\n  return (s ? -1 : 1) * m * Math.pow(2, e - mLen)\n}\n\nexports.write = function (buffer, value, offset, isLE, mLen, nBytes) {\n  var e, m, c\n  var eLen = (nBytes * 8) - mLen - 1\n  var eMax = (1 << eLen) - 1\n  var eBias = eMax >> 1\n  var rt = (mLen === 23 ? Math.pow(2, -24) - Math.pow(2, -77) : 0)\n  var i = isLE ? 0 : (nBytes - 1)\n  var d = isLE ? 1 : -1\n  var s = value < 0 || (value === 0 && 1 / value < 0) ? 1 : 0\n\n  value = Math.abs(value)\n\n  if (isNaN(value) || value === Infinity) {\n    m = isNaN(value) ? 1 : 0\n    e = eMax\n  } else {\n    e = Math.floor(Math.log(value) / Math.LN2)\n    if (value * (c = Math.pow(2, -e)) < 1) {\n      e--\n      c *= 2\n    }\n    if (e + eBias >= 1) {\n      value += rt / c\n    } else {\n      value += rt * Math.pow(2, 1 - eBias)\n    }\n    if (value * c >= 2) {\n      e++\n      c /= 2\n    }\n\n    if (e + eBias >= eMax) {\n      m = 0\n      e = eMax\n    } else if (e + eBias >= 1) {\n      m = ((value * c) - 1) * Math.pow(2, mLen)\n      e = e + eBias\n    } else {\n      m = value * Math.pow(2, eBias - 1) * Math.pow(2, mLen)\n      e = 0\n    }\n  }\n\n  for (; mLen >= 8; buffer[offset + i] = m & 0xff, i += d, m /= 256, mLen -= 8) {}\n\n  e = (e << mLen) | m\n  eLen += mLen\n  for (; eLen > 0; buffer[offset + i] = e & 0xff, i += d, e /= 256, eLen -= 8) {}\n\n  buffer[offset + i - d] |= s * 128\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/ieee754/index.js?");

/***/ }),

/***/ "./node_modules/inherits/inherits_browser.js":
/*!***************************************************!*\
  !*** ./node_modules/inherits/inherits_browser.js ***!
  \***************************************************/
/***/ ((module) => {

eval("if (typeof Object.create === 'function') {\n  // implementation from standard node.js 'util' module\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      ctor.prototype = Object.create(superCtor.prototype, {\n        constructor: {\n          value: ctor,\n          enumerable: false,\n          writable: true,\n          configurable: true\n        }\n      })\n    }\n  };\n} else {\n  // old school shim for old browsers\n  module.exports = function inherits(ctor, superCtor) {\n    if (superCtor) {\n      ctor.super_ = superCtor\n      var TempCtor = function () {}\n      TempCtor.prototype = superCtor.prototype\n      ctor.prototype = new TempCtor()\n      ctor.prototype.constructor = ctor\n    }\n  }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/inherits/inherits_browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/errors-browser.js":
/*!********************************************************!*\
  !*** ./node_modules/readable-stream/errors-browser.js ***!
  \********************************************************/
/***/ ((module) => {

"use strict";
eval("\n\nfunction _inheritsLoose(subClass, superClass) { subClass.prototype = Object.create(superClass.prototype); subClass.prototype.constructor = subClass; subClass.__proto__ = superClass; }\n\nvar codes = {};\n\nfunction createErrorType(code, message, Base) {\n  if (!Base) {\n    Base = Error;\n  }\n\n  function getMessage(arg1, arg2, arg3) {\n    if (typeof message === 'string') {\n      return message;\n    } else {\n      return message(arg1, arg2, arg3);\n    }\n  }\n\n  var NodeError =\n  /*#__PURE__*/\n  function (_Base) {\n    _inheritsLoose(NodeError, _Base);\n\n    function NodeError(arg1, arg2, arg3) {\n      return _Base.call(this, getMessage(arg1, arg2, arg3)) || this;\n    }\n\n    return NodeError;\n  }(Base);\n\n  NodeError.prototype.name = Base.name;\n  NodeError.prototype.code = code;\n  codes[code] = NodeError;\n} // https://github.com/nodejs/node/blob/v10.8.0/lib/internal/errors.js\n\n\nfunction oneOf(expected, thing) {\n  if (Array.isArray(expected)) {\n    var len = expected.length;\n    expected = expected.map(function (i) {\n      return String(i);\n    });\n\n    if (len > 2) {\n      return \"one of \".concat(thing, \" \").concat(expected.slice(0, len - 1).join(', '), \", or \") + expected[len - 1];\n    } else if (len === 2) {\n      return \"one of \".concat(thing, \" \").concat(expected[0], \" or \").concat(expected[1]);\n    } else {\n      return \"of \".concat(thing, \" \").concat(expected[0]);\n    }\n  } else {\n    return \"of \".concat(thing, \" \").concat(String(expected));\n  }\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/startsWith\n\n\nfunction startsWith(str, search, pos) {\n  return str.substr(!pos || pos < 0 ? 0 : +pos, search.length) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/endsWith\n\n\nfunction endsWith(str, search, this_len) {\n  if (this_len === undefined || this_len > str.length) {\n    this_len = str.length;\n  }\n\n  return str.substring(this_len - search.length, this_len) === search;\n} // https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/includes\n\n\nfunction includes(str, search, start) {\n  if (typeof start !== 'number') {\n    start = 0;\n  }\n\n  if (start + search.length > str.length) {\n    return false;\n  } else {\n    return str.indexOf(search, start) !== -1;\n  }\n}\n\ncreateErrorType('ERR_INVALID_OPT_VALUE', function (name, value) {\n  return 'The value \"' + value + '\" is invalid for option \"' + name + '\"';\n}, TypeError);\ncreateErrorType('ERR_INVALID_ARG_TYPE', function (name, expected, actual) {\n  // determiner: 'must be' or 'must not be'\n  var determiner;\n\n  if (typeof expected === 'string' && startsWith(expected, 'not ')) {\n    determiner = 'must not be';\n    expected = expected.replace(/^not /, '');\n  } else {\n    determiner = 'must be';\n  }\n\n  var msg;\n\n  if (endsWith(name, ' argument')) {\n    // For cases like 'first argument'\n    msg = \"The \".concat(name, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  } else {\n    var type = includes(name, '.') ? 'property' : 'argument';\n    msg = \"The \\\"\".concat(name, \"\\\" \").concat(type, \" \").concat(determiner, \" \").concat(oneOf(expected, 'type'));\n  }\n\n  msg += \". Received type \".concat(typeof actual);\n  return msg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_PUSH_AFTER_EOF', 'stream.push() after EOF');\ncreateErrorType('ERR_METHOD_NOT_IMPLEMENTED', function (name) {\n  return 'The ' + name + ' method is not implemented';\n});\ncreateErrorType('ERR_STREAM_PREMATURE_CLOSE', 'Premature close');\ncreateErrorType('ERR_STREAM_DESTROYED', function (name) {\n  return 'Cannot call ' + name + ' after a stream was destroyed';\n});\ncreateErrorType('ERR_MULTIPLE_CALLBACK', 'Callback called multiple times');\ncreateErrorType('ERR_STREAM_CANNOT_PIPE', 'Cannot pipe, not readable');\ncreateErrorType('ERR_STREAM_WRITE_AFTER_END', 'write after end');\ncreateErrorType('ERR_STREAM_NULL_VALUES', 'May not write null values to stream', TypeError);\ncreateErrorType('ERR_UNKNOWN_ENCODING', function (arg) {\n  return 'Unknown encoding: ' + arg;\n}, TypeError);\ncreateErrorType('ERR_STREAM_UNSHIFT_AFTER_END_EVENT', 'stream.unshift() after end event');\nmodule.exports.codes = codes;\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/errors-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_duplex.js":
/*!************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_duplex.js ***!
  \************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a duplex stream is just a stream that is both readable and writable.\n// Since JS doesn't have multiple prototypal inheritance, this class\n// prototypally inherits from Readable, and then parasitically from\n// Writable.\n\n/*<replacement>*/\n\nvar objectKeys = Object.keys || function (obj) {\n  var keys = [];\n\n  for (var key in obj) {\n    keys.push(key);\n  }\n\n  return keys;\n};\n/*</replacement>*/\n\n\nmodule.exports = Duplex;\n\nvar Readable = __webpack_require__(/*! ./_stream_readable */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\n\nvar Writable = __webpack_require__(/*! ./_stream_writable */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\n\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Duplex, Readable);\n\n{\n  // Allow the keys array to be GC'ed.\n  var keys = objectKeys(Writable.prototype);\n\n  for (var v = 0; v < keys.length; v++) {\n    var method = keys[v];\n    if (!Duplex.prototype[method]) Duplex.prototype[method] = Writable.prototype[method];\n  }\n}\n\nfunction Duplex(options) {\n  if (!(this instanceof Duplex)) return new Duplex(options);\n  Readable.call(this, options);\n  Writable.call(this, options);\n  this.allowHalfOpen = true;\n\n  if (options) {\n    if (options.readable === false) this.readable = false;\n    if (options.writable === false) this.writable = false;\n\n    if (options.allowHalfOpen === false) {\n      this.allowHalfOpen = false;\n      this.once('end', onend);\n    }\n  }\n}\n\nObject.defineProperty(Duplex.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\nObject.defineProperty(Duplex.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n}); // the no-half-open enforcer\n\nfunction onend() {\n  // If the writable side ended, then we're ok.\n  if (this._writableState.ended) return; // no more data can be written.\n  // But allow more writes to happen in this tick.\n\n  process.nextTick(onEndNT, this);\n}\n\nfunction onEndNT(self) {\n  self.end();\n}\n\nObject.defineProperty(Duplex.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed && this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (this._readableState === undefined || this._writableState === undefined) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n    this._writableState.destroyed = value;\n  }\n});\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/_stream_duplex.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_passthrough.js":
/*!*****************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_passthrough.js ***!
  \*****************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a passthrough stream.\n// basically just the most minimal sort of Transform stream.\n// Every written chunk gets output as-is.\n\n\nmodule.exports = PassThrough;\n\nvar Transform = __webpack_require__(/*! ./_stream_transform */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\n\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(PassThrough, Transform);\n\nfunction PassThrough(options) {\n  if (!(this instanceof PassThrough)) return new PassThrough(options);\n  Transform.call(this, options);\n}\n\nPassThrough.prototype._transform = function (chunk, encoding, cb) {\n  cb(null, chunk);\n};\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/_stream_passthrough.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_readable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_readable.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n\n\nmodule.exports = Readable;\n/*<replacement>*/\n\nvar Duplex;\n/*</replacement>*/\n\nReadable.ReadableState = ReadableState;\n/*<replacement>*/\n\nvar EE = (__webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter);\n\nvar EElistenerCount = function EElistenerCount(emitter, type) {\n  return emitter.listeners(type).length;\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\n\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n\nvar Buffer = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n\nvar OurUint8Array = __webpack_require__.g.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n/*<replacement>*/\n\n\nvar debugUtil = __webpack_require__(/*! util */ \"?d17e\");\n\nvar debug;\n\nif (debugUtil && debugUtil.debuglog) {\n  debug = debugUtil.debuglog('stream');\n} else {\n  debug = function debug() {};\n}\n/*</replacement>*/\n\n\nvar BufferList = __webpack_require__(/*! ./internal/streams/buffer_list */ \"./node_modules/readable-stream/lib/internal/streams/buffer_list.js\");\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\"),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_STREAM_PUSH_AFTER_EOF = _require$codes.ERR_STREAM_PUSH_AFTER_EOF,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_STREAM_UNSHIFT_AFTER_END_EVENT = _require$codes.ERR_STREAM_UNSHIFT_AFTER_END_EVENT; // Lazy loaded to improve the startup performance.\n\n\nvar StringDecoder;\nvar createReadableStreamAsyncIterator;\nvar from;\n\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Readable, Stream);\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\nvar kProxyEvents = ['error', 'close', 'destroy', 'pause', 'resume'];\n\nfunction prependListener(emitter, event, fn) {\n  // Sadly this is not cacheable as some libraries bundle their own\n  // event emitter implementation with them.\n  if (typeof emitter.prependListener === 'function') return emitter.prependListener(event, fn); // This is a hack to make sure that our error handler is attached before any\n  // userland ones.  NEVER DO THIS. This is here only because this code needs\n  // to continue to work with older versions of Node.js that do not include\n  // the prependListener() method. The goal is to eventually remove this hack.\n\n  if (!emitter._events || !emitter._events[event]) emitter.on(event, fn);else if (Array.isArray(emitter._events[event])) emitter._events[event].unshift(fn);else emitter._events[event] = [fn, emitter._events[event]];\n}\n\nfunction ReadableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream.\n  // These options can be provided separately as readableXXX and writableXXX.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag. Used to make read(n) ignore n and to\n  // make all the buffer merging and length checks go away\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.readableObjectMode; // the point at which it stops calling _read() to fill the buffer\n  // Note: 0 is a valid value, means \"don't call _read preemptively ever\"\n\n  this.highWaterMark = getHighWaterMark(this, options, 'readableHighWaterMark', isDuplex); // A linked list is used to store data chunks instead of an array because the\n  // linked list can remove elements from the beginning faster than\n  // array.shift()\n\n  this.buffer = new BufferList();\n  this.length = 0;\n  this.pipes = null;\n  this.pipesCount = 0;\n  this.flowing = null;\n  this.ended = false;\n  this.endEmitted = false;\n  this.reading = false; // a flag to be able to tell if the event 'readable'/'data' is emitted\n  // immediately, or on a later tick.  We set this to true at first, because\n  // any actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first read call.\n\n  this.sync = true; // whenever we return null, then we set a flag to say\n  // that we're awaiting a 'readable' event emission.\n\n  this.needReadable = false;\n  this.emittedReadable = false;\n  this.readableListening = false;\n  this.resumeScheduled = false;\n  this.paused = true; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'end' (and potentially 'finish')\n\n  this.autoDestroy = !!options.autoDestroy; // has it been destroyed\n\n  this.destroyed = false; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // the number of writers that are awaiting a drain event in .pipe()s\n\n  this.awaitDrain = 0; // if true, a maybeReadMore has been scheduled\n\n  this.readingMore = false;\n  this.decoder = null;\n  this.encoding = null;\n\n  if (options.encoding) {\n    if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n    this.decoder = new StringDecoder(options.encoding);\n    this.encoding = options.encoding;\n  }\n}\n\nfunction Readable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  if (!(this instanceof Readable)) return new Readable(options); // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the ReadableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  this._readableState = new ReadableState(options, this, isDuplex); // legacy\n\n  this.readable = true;\n\n  if (options) {\n    if (typeof options.read === 'function') this._read = options.read;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n  }\n\n  Stream.call(this);\n}\n\nObject.defineProperty(Readable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._readableState === undefined) {\n      return false;\n    }\n\n    return this._readableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._readableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._readableState.destroyed = value;\n  }\n});\nReadable.prototype.destroy = destroyImpl.destroy;\nReadable.prototype._undestroy = destroyImpl.undestroy;\n\nReadable.prototype._destroy = function (err, cb) {\n  cb(err);\n}; // Manually shove something into the read() buffer.\n// This returns true if the highWaterMark has not been hit yet,\n// similar to how Writable.write() returns true if you should\n// write() some more.\n\n\nReadable.prototype.push = function (chunk, encoding) {\n  var state = this._readableState;\n  var skipChunkCheck;\n\n  if (!state.objectMode) {\n    if (typeof chunk === 'string') {\n      encoding = encoding || state.defaultEncoding;\n\n      if (encoding !== state.encoding) {\n        chunk = Buffer.from(chunk, encoding);\n        encoding = '';\n      }\n\n      skipChunkCheck = true;\n    }\n  } else {\n    skipChunkCheck = true;\n  }\n\n  return readableAddChunk(this, chunk, encoding, false, skipChunkCheck);\n}; // Unshift should *always* be something directly out of read()\n\n\nReadable.prototype.unshift = function (chunk) {\n  return readableAddChunk(this, chunk, null, true, false);\n};\n\nfunction readableAddChunk(stream, chunk, encoding, addToFront, skipChunkCheck) {\n  debug('readableAddChunk', chunk);\n  var state = stream._readableState;\n\n  if (chunk === null) {\n    state.reading = false;\n    onEofChunk(stream, state);\n  } else {\n    var er;\n    if (!skipChunkCheck) er = chunkInvalid(state, chunk);\n\n    if (er) {\n      errorOrDestroy(stream, er);\n    } else if (state.objectMode || chunk && chunk.length > 0) {\n      if (typeof chunk !== 'string' && !state.objectMode && Object.getPrototypeOf(chunk) !== Buffer.prototype) {\n        chunk = _uint8ArrayToBuffer(chunk);\n      }\n\n      if (addToFront) {\n        if (state.endEmitted) errorOrDestroy(stream, new ERR_STREAM_UNSHIFT_AFTER_END_EVENT());else addChunk(stream, state, chunk, true);\n      } else if (state.ended) {\n        errorOrDestroy(stream, new ERR_STREAM_PUSH_AFTER_EOF());\n      } else if (state.destroyed) {\n        return false;\n      } else {\n        state.reading = false;\n\n        if (state.decoder && !encoding) {\n          chunk = state.decoder.write(chunk);\n          if (state.objectMode || chunk.length !== 0) addChunk(stream, state, chunk, false);else maybeReadMore(stream, state);\n        } else {\n          addChunk(stream, state, chunk, false);\n        }\n      }\n    } else if (!addToFront) {\n      state.reading = false;\n      maybeReadMore(stream, state);\n    }\n  } // We can push more data if we are below the highWaterMark.\n  // Also, if we have no data yet, we can stand some more bytes.\n  // This is to work around cases where hwm=0, such as the repl.\n\n\n  return !state.ended && (state.length < state.highWaterMark || state.length === 0);\n}\n\nfunction addChunk(stream, state, chunk, addToFront) {\n  if (state.flowing && state.length === 0 && !state.sync) {\n    state.awaitDrain = 0;\n    stream.emit('data', chunk);\n  } else {\n    // update the buffer info.\n    state.length += state.objectMode ? 1 : chunk.length;\n    if (addToFront) state.buffer.unshift(chunk);else state.buffer.push(chunk);\n    if (state.needReadable) emitReadable(stream);\n  }\n\n  maybeReadMore(stream, state);\n}\n\nfunction chunkInvalid(state, chunk) {\n  var er;\n\n  if (!_isUint8Array(chunk) && typeof chunk !== 'string' && chunk !== undefined && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer', 'Uint8Array'], chunk);\n  }\n\n  return er;\n}\n\nReadable.prototype.isPaused = function () {\n  return this._readableState.flowing === false;\n}; // backwards compatibility.\n\n\nReadable.prototype.setEncoding = function (enc) {\n  if (!StringDecoder) StringDecoder = (__webpack_require__(/*! string_decoder/ */ \"./node_modules/string_decoder/lib/string_decoder.js\").StringDecoder);\n  var decoder = new StringDecoder(enc);\n  this._readableState.decoder = decoder; // If setEncoding(null), decoder.encoding equals utf8\n\n  this._readableState.encoding = this._readableState.decoder.encoding; // Iterate over current buffer to convert already stored Buffers:\n\n  var p = this._readableState.buffer.head;\n  var content = '';\n\n  while (p !== null) {\n    content += decoder.write(p.data);\n    p = p.next;\n  }\n\n  this._readableState.buffer.clear();\n\n  if (content !== '') this._readableState.buffer.push(content);\n  this._readableState.length = content.length;\n  return this;\n}; // Don't raise the hwm > 1GB\n\n\nvar MAX_HWM = 0x40000000;\n\nfunction computeNewHighWaterMark(n) {\n  if (n >= MAX_HWM) {\n    // TODO(ronag): Throw ERR_VALUE_OUT_OF_RANGE.\n    n = MAX_HWM;\n  } else {\n    // Get the next highest power of 2 to prevent increasing hwm excessively in\n    // tiny amounts\n    n--;\n    n |= n >>> 1;\n    n |= n >>> 2;\n    n |= n >>> 4;\n    n |= n >>> 8;\n    n |= n >>> 16;\n    n++;\n  }\n\n  return n;\n} // This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\n\nfunction howMuchToRead(n, state) {\n  if (n <= 0 || state.length === 0 && state.ended) return 0;\n  if (state.objectMode) return 1;\n\n  if (n !== n) {\n    // Only flow one buffer at a time\n    if (state.flowing && state.length) return state.buffer.head.data.length;else return state.length;\n  } // If we're asking for more than the current hwm, then raise the hwm.\n\n\n  if (n > state.highWaterMark) state.highWaterMark = computeNewHighWaterMark(n);\n  if (n <= state.length) return n; // Don't have enough\n\n  if (!state.ended) {\n    state.needReadable = true;\n    return 0;\n  }\n\n  return state.length;\n} // you can override either this method, or the async _read(n) below.\n\n\nReadable.prototype.read = function (n) {\n  debug('read', n);\n  n = parseInt(n, 10);\n  var state = this._readableState;\n  var nOrig = n;\n  if (n !== 0) state.emittedReadable = false; // if we're doing read(0) to trigger a readable event, but we\n  // already have a bunch of data in the buffer, then just trigger\n  // the 'readable' event and move on.\n\n  if (n === 0 && state.needReadable && ((state.highWaterMark !== 0 ? state.length >= state.highWaterMark : state.length > 0) || state.ended)) {\n    debug('read: emitReadable', state.length, state.ended);\n    if (state.length === 0 && state.ended) endReadable(this);else emitReadable(this);\n    return null;\n  }\n\n  n = howMuchToRead(n, state); // if we've ended, and we're now clear, then finish it up.\n\n  if (n === 0 && state.ended) {\n    if (state.length === 0) endReadable(this);\n    return null;\n  } // All the actual chunk generation logic needs to be\n  // *below* the call to _read.  The reason is that in certain\n  // synthetic stream cases, such as passthrough streams, _read\n  // may be a completely synchronous operation which may change\n  // the state of the read buffer, providing enough data when\n  // before there was *not* enough.\n  //\n  // So, the steps are:\n  // 1. Figure out what the state of things will be after we do\n  // a read from the buffer.\n  //\n  // 2. If that resulting state will trigger a _read, then call _read.\n  // Note that this may be asynchronous, or synchronous.  Yes, it is\n  // deeply ugly to write APIs this way, but that still doesn't mean\n  // that the Readable class should behave improperly, as streams are\n  // designed to be sync/async agnostic.\n  // Take note if the _read call is sync or async (ie, if the read call\n  // has returned yet), so that we know whether or not it's safe to emit\n  // 'readable' etc.\n  //\n  // 3. Actually pull the requested chunks out of the buffer and return.\n  // if we need a readable event, then we need to do some reading.\n\n\n  var doRead = state.needReadable;\n  debug('need readable', doRead); // if we currently have less than the highWaterMark, then also read some\n\n  if (state.length === 0 || state.length - n < state.highWaterMark) {\n    doRead = true;\n    debug('length less than watermark', doRead);\n  } // however, if we've ended, then there's no point, and if we're already\n  // reading, then it's unnecessary.\n\n\n  if (state.ended || state.reading) {\n    doRead = false;\n    debug('reading or ended', doRead);\n  } else if (doRead) {\n    debug('do read');\n    state.reading = true;\n    state.sync = true; // if the length is currently zero, then we *need* a readable event.\n\n    if (state.length === 0) state.needReadable = true; // call internal read method\n\n    this._read(state.highWaterMark);\n\n    state.sync = false; // If _read pushed data synchronously, then `reading` will be false,\n    // and we need to re-evaluate how much data we can return to the user.\n\n    if (!state.reading) n = howMuchToRead(nOrig, state);\n  }\n\n  var ret;\n  if (n > 0) ret = fromList(n, state);else ret = null;\n\n  if (ret === null) {\n    state.needReadable = state.length <= state.highWaterMark;\n    n = 0;\n  } else {\n    state.length -= n;\n    state.awaitDrain = 0;\n  }\n\n  if (state.length === 0) {\n    // If we have nothing in the buffer, then we want to know\n    // as soon as we *do* get something into the buffer.\n    if (!state.ended) state.needReadable = true; // If we tried to read() past the EOF, then emit end on the next tick.\n\n    if (nOrig !== n && state.ended) endReadable(this);\n  }\n\n  if (ret !== null) this.emit('data', ret);\n  return ret;\n};\n\nfunction onEofChunk(stream, state) {\n  debug('onEofChunk');\n  if (state.ended) return;\n\n  if (state.decoder) {\n    var chunk = state.decoder.end();\n\n    if (chunk && chunk.length) {\n      state.buffer.push(chunk);\n      state.length += state.objectMode ? 1 : chunk.length;\n    }\n  }\n\n  state.ended = true;\n\n  if (state.sync) {\n    // if we are sync, wait until next tick to emit the data.\n    // Otherwise we risk emitting data in the flow()\n    // the readable code triggers during a read() call\n    emitReadable(stream);\n  } else {\n    // emit 'readable' now to make sure it gets picked up.\n    state.needReadable = false;\n\n    if (!state.emittedReadable) {\n      state.emittedReadable = true;\n      emitReadable_(stream);\n    }\n  }\n} // Don't emit readable right away in sync mode, because this can trigger\n// another read() call => stack overflow.  This way, it might trigger\n// a nextTick recursion warning, but that's not so bad.\n\n\nfunction emitReadable(stream) {\n  var state = stream._readableState;\n  debug('emitReadable', state.needReadable, state.emittedReadable);\n  state.needReadable = false;\n\n  if (!state.emittedReadable) {\n    debug('emitReadable', state.flowing);\n    state.emittedReadable = true;\n    process.nextTick(emitReadable_, stream);\n  }\n}\n\nfunction emitReadable_(stream) {\n  var state = stream._readableState;\n  debug('emitReadable_', state.destroyed, state.length, state.ended);\n\n  if (!state.destroyed && (state.length || state.ended)) {\n    stream.emit('readable');\n    state.emittedReadable = false;\n  } // The stream needs another readable event if\n  // 1. It is not flowing, as the flow mechanism will take\n  //    care of it.\n  // 2. It is not ended.\n  // 3. It is below the highWaterMark, so we can schedule\n  //    another readable later.\n\n\n  state.needReadable = !state.flowing && !state.ended && state.length <= state.highWaterMark;\n  flow(stream);\n} // at this point, the user has presumably seen the 'readable' event,\n// and called read() to consume some data.  that may have triggered\n// in turn another _read(n) call, in which case reading = true if\n// it's in progress.\n// However, if we're not ended, or reading, and the length < hwm,\n// then go ahead and try to read some more preemptively.\n\n\nfunction maybeReadMore(stream, state) {\n  if (!state.readingMore) {\n    state.readingMore = true;\n    process.nextTick(maybeReadMore_, stream, state);\n  }\n}\n\nfunction maybeReadMore_(stream, state) {\n  // Attempt to read more data if we should.\n  //\n  // The conditions for reading more data are (one of):\n  // - Not enough data buffered (state.length < state.highWaterMark). The loop\n  //   is responsible for filling the buffer with enough data if such data\n  //   is available. If highWaterMark is 0 and we are not in the flowing mode\n  //   we should _not_ attempt to buffer any extra data. We'll get more data\n  //   when the stream consumer calls read() instead.\n  // - No data in the buffer, and the stream is in flowing mode. In this mode\n  //   the loop below is responsible for ensuring read() is called. Failing to\n  //   call read here would abort the flow and there's no other mechanism for\n  //   continuing the flow if the stream consumer has just subscribed to the\n  //   'data' event.\n  //\n  // In addition to the above conditions to keep reading data, the following\n  // conditions prevent the data from being read:\n  // - The stream has ended (state.ended).\n  // - There is already a pending 'read' operation (state.reading). This is a\n  //   case where the the stream has called the implementation defined _read()\n  //   method, but they are processing the call asynchronously and have _not_\n  //   called push() with new data. In this case we skip performing more\n  //   read()s. The execution ends in this method again after the _read() ends\n  //   up calling push() with more data.\n  while (!state.reading && !state.ended && (state.length < state.highWaterMark || state.flowing && state.length === 0)) {\n    var len = state.length;\n    debug('maybeReadMore read 0');\n    stream.read(0);\n    if (len === state.length) // didn't get any data, stop spinning.\n      break;\n  }\n\n  state.readingMore = false;\n} // abstract method.  to be overridden in specific implementation classes.\n// call cb(er, data) where data is <= n in length.\n// for virtual (non-string, non-buffer) streams, \"length\" is somewhat\n// arbitrary, and perhaps not very meaningful.\n\n\nReadable.prototype._read = function (n) {\n  errorOrDestroy(this, new ERR_METHOD_NOT_IMPLEMENTED('_read()'));\n};\n\nReadable.prototype.pipe = function (dest, pipeOpts) {\n  var src = this;\n  var state = this._readableState;\n\n  switch (state.pipesCount) {\n    case 0:\n      state.pipes = dest;\n      break;\n\n    case 1:\n      state.pipes = [state.pipes, dest];\n      break;\n\n    default:\n      state.pipes.push(dest);\n      break;\n  }\n\n  state.pipesCount += 1;\n  debug('pipe count=%d opts=%j', state.pipesCount, pipeOpts);\n  var doEnd = (!pipeOpts || pipeOpts.end !== false) && dest !== process.stdout && dest !== process.stderr;\n  var endFn = doEnd ? onend : unpipe;\n  if (state.endEmitted) process.nextTick(endFn);else src.once('end', endFn);\n  dest.on('unpipe', onunpipe);\n\n  function onunpipe(readable, unpipeInfo) {\n    debug('onunpipe');\n\n    if (readable === src) {\n      if (unpipeInfo && unpipeInfo.hasUnpiped === false) {\n        unpipeInfo.hasUnpiped = true;\n        cleanup();\n      }\n    }\n  }\n\n  function onend() {\n    debug('onend');\n    dest.end();\n  } // when the dest drains, it reduces the awaitDrain counter\n  // on the source.  This would be more elegant with a .once()\n  // handler in flow(), but adding and removing repeatedly is\n  // too slow.\n\n\n  var ondrain = pipeOnDrain(src);\n  dest.on('drain', ondrain);\n  var cleanedUp = false;\n\n  function cleanup() {\n    debug('cleanup'); // cleanup event handlers once the pipe is broken\n\n    dest.removeListener('close', onclose);\n    dest.removeListener('finish', onfinish);\n    dest.removeListener('drain', ondrain);\n    dest.removeListener('error', onerror);\n    dest.removeListener('unpipe', onunpipe);\n    src.removeListener('end', onend);\n    src.removeListener('end', unpipe);\n    src.removeListener('data', ondata);\n    cleanedUp = true; // if the reader is waiting for a drain event from this\n    // specific writer, then it would cause it to never start\n    // flowing again.\n    // So, if this is awaiting a drain, then we just call it now.\n    // If we don't know, then assume that we are waiting for one.\n\n    if (state.awaitDrain && (!dest._writableState || dest._writableState.needDrain)) ondrain();\n  }\n\n  src.on('data', ondata);\n\n  function ondata(chunk) {\n    debug('ondata');\n    var ret = dest.write(chunk);\n    debug('dest.write', ret);\n\n    if (ret === false) {\n      // If the user unpiped during `dest.write()`, it is possible\n      // to get stuck in a permanently paused state if that write\n      // also returned false.\n      // => Check whether `dest` is still a piping destination.\n      if ((state.pipesCount === 1 && state.pipes === dest || state.pipesCount > 1 && indexOf(state.pipes, dest) !== -1) && !cleanedUp) {\n        debug('false write response, pause', state.awaitDrain);\n        state.awaitDrain++;\n      }\n\n      src.pause();\n    }\n  } // if the dest has an error, then stop piping into it.\n  // however, don't suppress the throwing behavior for this.\n\n\n  function onerror(er) {\n    debug('onerror', er);\n    unpipe();\n    dest.removeListener('error', onerror);\n    if (EElistenerCount(dest, 'error') === 0) errorOrDestroy(dest, er);\n  } // Make sure our error handler is attached before userland ones.\n\n\n  prependListener(dest, 'error', onerror); // Both close and finish should trigger unpipe, but only once.\n\n  function onclose() {\n    dest.removeListener('finish', onfinish);\n    unpipe();\n  }\n\n  dest.once('close', onclose);\n\n  function onfinish() {\n    debug('onfinish');\n    dest.removeListener('close', onclose);\n    unpipe();\n  }\n\n  dest.once('finish', onfinish);\n\n  function unpipe() {\n    debug('unpipe');\n    src.unpipe(dest);\n  } // tell the dest that it's being piped to\n\n\n  dest.emit('pipe', src); // start the flow if it hasn't been started already.\n\n  if (!state.flowing) {\n    debug('pipe resume');\n    src.resume();\n  }\n\n  return dest;\n};\n\nfunction pipeOnDrain(src) {\n  return function pipeOnDrainFunctionResult() {\n    var state = src._readableState;\n    debug('pipeOnDrain', state.awaitDrain);\n    if (state.awaitDrain) state.awaitDrain--;\n\n    if (state.awaitDrain === 0 && EElistenerCount(src, 'data')) {\n      state.flowing = true;\n      flow(src);\n    }\n  };\n}\n\nReadable.prototype.unpipe = function (dest) {\n  var state = this._readableState;\n  var unpipeInfo = {\n    hasUnpiped: false\n  }; // if we're not piping anywhere, then do nothing.\n\n  if (state.pipesCount === 0) return this; // just one destination.  most common case.\n\n  if (state.pipesCount === 1) {\n    // passed in one, but it's not the right one.\n    if (dest && dest !== state.pipes) return this;\n    if (!dest) dest = state.pipes; // got a match.\n\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n    if (dest) dest.emit('unpipe', this, unpipeInfo);\n    return this;\n  } // slow case. multiple pipe destinations.\n\n\n  if (!dest) {\n    // remove all.\n    var dests = state.pipes;\n    var len = state.pipesCount;\n    state.pipes = null;\n    state.pipesCount = 0;\n    state.flowing = false;\n\n    for (var i = 0; i < len; i++) {\n      dests[i].emit('unpipe', this, {\n        hasUnpiped: false\n      });\n    }\n\n    return this;\n  } // try to find the right one.\n\n\n  var index = indexOf(state.pipes, dest);\n  if (index === -1) return this;\n  state.pipes.splice(index, 1);\n  state.pipesCount -= 1;\n  if (state.pipesCount === 1) state.pipes = state.pipes[0];\n  dest.emit('unpipe', this, unpipeInfo);\n  return this;\n}; // set up data events if they are asked for\n// Ensure readable listeners eventually get something\n\n\nReadable.prototype.on = function (ev, fn) {\n  var res = Stream.prototype.on.call(this, ev, fn);\n  var state = this._readableState;\n\n  if (ev === 'data') {\n    // update readableListening so that resume() may be a no-op\n    // a few lines down. This is needed to support once('readable').\n    state.readableListening = this.listenerCount('readable') > 0; // Try start flowing on next tick if stream isn't explicitly paused\n\n    if (state.flowing !== false) this.resume();\n  } else if (ev === 'readable') {\n    if (!state.endEmitted && !state.readableListening) {\n      state.readableListening = state.needReadable = true;\n      state.flowing = false;\n      state.emittedReadable = false;\n      debug('on readable', state.length, state.reading);\n\n      if (state.length) {\n        emitReadable(this);\n      } else if (!state.reading) {\n        process.nextTick(nReadingNextTick, this);\n      }\n    }\n  }\n\n  return res;\n};\n\nReadable.prototype.addListener = Readable.prototype.on;\n\nReadable.prototype.removeListener = function (ev, fn) {\n  var res = Stream.prototype.removeListener.call(this, ev, fn);\n\n  if (ev === 'readable') {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nReadable.prototype.removeAllListeners = function (ev) {\n  var res = Stream.prototype.removeAllListeners.apply(this, arguments);\n\n  if (ev === 'readable' || ev === undefined) {\n    // We need to check if there is someone still listening to\n    // readable and reset the state. However this needs to happen\n    // after readable has been emitted but before I/O (nextTick) to\n    // support once('readable', fn) cycles. This means that calling\n    // resume within the same tick will have no\n    // effect.\n    process.nextTick(updateReadableListening, this);\n  }\n\n  return res;\n};\n\nfunction updateReadableListening(self) {\n  var state = self._readableState;\n  state.readableListening = self.listenerCount('readable') > 0;\n\n  if (state.resumeScheduled && !state.paused) {\n    // flowing needs to be set to true now, otherwise\n    // the upcoming resume will not flow.\n    state.flowing = true; // crude way to check if we should resume\n  } else if (self.listenerCount('data') > 0) {\n    self.resume();\n  }\n}\n\nfunction nReadingNextTick(self) {\n  debug('readable nexttick read 0');\n  self.read(0);\n} // pause() and resume() are remnants of the legacy readable stream API\n// If the user uses them, then switch into old mode.\n\n\nReadable.prototype.resume = function () {\n  var state = this._readableState;\n\n  if (!state.flowing) {\n    debug('resume'); // we flow only if there is no one listening\n    // for readable, but we still have to call\n    // resume()\n\n    state.flowing = !state.readableListening;\n    resume(this, state);\n  }\n\n  state.paused = false;\n  return this;\n};\n\nfunction resume(stream, state) {\n  if (!state.resumeScheduled) {\n    state.resumeScheduled = true;\n    process.nextTick(resume_, stream, state);\n  }\n}\n\nfunction resume_(stream, state) {\n  debug('resume', state.reading);\n\n  if (!state.reading) {\n    stream.read(0);\n  }\n\n  state.resumeScheduled = false;\n  stream.emit('resume');\n  flow(stream);\n  if (state.flowing && !state.reading) stream.read(0);\n}\n\nReadable.prototype.pause = function () {\n  debug('call pause flowing=%j', this._readableState.flowing);\n\n  if (this._readableState.flowing !== false) {\n    debug('pause');\n    this._readableState.flowing = false;\n    this.emit('pause');\n  }\n\n  this._readableState.paused = true;\n  return this;\n};\n\nfunction flow(stream) {\n  var state = stream._readableState;\n  debug('flow', state.flowing);\n\n  while (state.flowing && stream.read() !== null) {\n    ;\n  }\n} // wrap an old-style stream as the async data source.\n// This is *not* part of the readable stream interface.\n// It is an ugly unfortunate mess of history.\n\n\nReadable.prototype.wrap = function (stream) {\n  var _this = this;\n\n  var state = this._readableState;\n  var paused = false;\n  stream.on('end', function () {\n    debug('wrapped end');\n\n    if (state.decoder && !state.ended) {\n      var chunk = state.decoder.end();\n      if (chunk && chunk.length) _this.push(chunk);\n    }\n\n    _this.push(null);\n  });\n  stream.on('data', function (chunk) {\n    debug('wrapped data');\n    if (state.decoder) chunk = state.decoder.write(chunk); // don't skip over falsy values in objectMode\n\n    if (state.objectMode && (chunk === null || chunk === undefined)) return;else if (!state.objectMode && (!chunk || !chunk.length)) return;\n\n    var ret = _this.push(chunk);\n\n    if (!ret) {\n      paused = true;\n      stream.pause();\n    }\n  }); // proxy all the other methods.\n  // important when wrapping filters and duplexes.\n\n  for (var i in stream) {\n    if (this[i] === undefined && typeof stream[i] === 'function') {\n      this[i] = function methodWrap(method) {\n        return function methodWrapReturnFunction() {\n          return stream[method].apply(stream, arguments);\n        };\n      }(i);\n    }\n  } // proxy certain important events.\n\n\n  for (var n = 0; n < kProxyEvents.length; n++) {\n    stream.on(kProxyEvents[n], this.emit.bind(this, kProxyEvents[n]));\n  } // when we try to consume some more bytes, simply unpause the\n  // underlying stream.\n\n\n  this._read = function (n) {\n    debug('wrapped _read', n);\n\n    if (paused) {\n      paused = false;\n      stream.resume();\n    }\n  };\n\n  return this;\n};\n\nif (typeof Symbol === 'function') {\n  Readable.prototype[Symbol.asyncIterator] = function () {\n    if (createReadableStreamAsyncIterator === undefined) {\n      createReadableStreamAsyncIterator = __webpack_require__(/*! ./internal/streams/async_iterator */ \"./node_modules/readable-stream/lib/internal/streams/async_iterator.js\");\n    }\n\n    return createReadableStreamAsyncIterator(this);\n  };\n}\n\nObject.defineProperty(Readable.prototype, 'readableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.highWaterMark;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState && this._readableState.buffer;\n  }\n});\nObject.defineProperty(Readable.prototype, 'readableFlowing', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.flowing;\n  },\n  set: function set(state) {\n    if (this._readableState) {\n      this._readableState.flowing = state;\n    }\n  }\n}); // exposed for testing purposes only.\n\nReadable._fromList = fromList;\nObject.defineProperty(Readable.prototype, 'readableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._readableState.length;\n  }\n}); // Pluck off n bytes from an array of buffers.\n// Length is the combined lengths of all the buffers in the list.\n// This function is designed to be inlinable, so please take care when making\n// changes to the function body.\n\nfunction fromList(n, state) {\n  // nothing buffered\n  if (state.length === 0) return null;\n  var ret;\n  if (state.objectMode) ret = state.buffer.shift();else if (!n || n >= state.length) {\n    // read it all, truncate the list\n    if (state.decoder) ret = state.buffer.join('');else if (state.buffer.length === 1) ret = state.buffer.first();else ret = state.buffer.concat(state.length);\n    state.buffer.clear();\n  } else {\n    // read part of list\n    ret = state.buffer.consume(n, state.decoder);\n  }\n  return ret;\n}\n\nfunction endReadable(stream) {\n  var state = stream._readableState;\n  debug('endReadable', state.endEmitted);\n\n  if (!state.endEmitted) {\n    state.ended = true;\n    process.nextTick(endReadableNT, state, stream);\n  }\n}\n\nfunction endReadableNT(state, stream) {\n  debug('endReadableNT', state.endEmitted, state.length); // Check that we didn't get one last unshift.\n\n  if (!state.endEmitted && state.length === 0) {\n    state.endEmitted = true;\n    stream.readable = false;\n    stream.emit('end');\n\n    if (state.autoDestroy) {\n      // In case of duplex streams we need a way to detect\n      // if the writable side is ready for autoDestroy as well\n      var wState = stream._writableState;\n\n      if (!wState || wState.autoDestroy && wState.finished) {\n        stream.destroy();\n      }\n    }\n  }\n}\n\nif (typeof Symbol === 'function') {\n  Readable.from = function (iterable, opts) {\n    if (from === undefined) {\n      from = __webpack_require__(/*! ./internal/streams/from */ \"./node_modules/readable-stream/lib/internal/streams/from-browser.js\");\n    }\n\n    return from(Readable, iterable, opts);\n  };\n}\n\nfunction indexOf(xs, x) {\n  for (var i = 0, l = xs.length; i < l; i++) {\n    if (xs[i] === x) return i;\n  }\n\n  return -1;\n}\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/_stream_readable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_transform.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_transform.js ***!
  \***************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// a transform stream is a readable/writable stream where you do\n// something with the data.  Sometimes it's called a \"filter\",\n// but that's not a great name for it, since that implies a thing where\n// some bits pass through, and others are simply ignored.  (That would\n// be a valid example of a transform, of course.)\n//\n// While the output is causally related to the input, it's not a\n// necessarily symmetric or synchronous transformation.  For example,\n// a zlib stream might take multiple plain-text writes(), and then\n// emit a single compressed chunk some time in the future.\n//\n// Here's how this works:\n//\n// The Transform stream has all the aspects of the readable and writable\n// stream classes.  When you write(chunk), that calls _write(chunk,cb)\n// internally, and returns false if there's a lot of pending writes\n// buffered up.  When you call read(), that calls _read(n) until\n// there's enough pending readable data buffered up.\n//\n// In a transform stream, the written data is placed in a buffer.  When\n// _read(n) is called, it transforms the queued up data, calling the\n// buffered _write cb's as it consumes chunks.  If consuming a single\n// written chunk would result in multiple output chunks, then the first\n// outputted bit calls the readcb, and subsequent chunks just go into\n// the read buffer, and will cause it to emit 'readable' if necessary.\n//\n// This way, back-pressure is actually determined by the reading side,\n// since _read has to be called to start processing a new chunk.  However,\n// a pathological inflate type of transform can cause excessive buffering\n// here.  For example, imagine a stream where every byte of input is\n// interpreted as an integer from 0-255, and then results in that many\n// bytes of output.  Writing the 4 bytes {ff,ff,ff,ff} would result in\n// 1kb of data being output.  In this case, you could write a very small\n// amount of input, and end up with a very large amount of output.  In\n// such a pathological inflating mechanism, there'd be no way to tell\n// the system to stop doing the transform.  A single 4MB write could\n// cause the system to run out of memory.\n//\n// However, even in such a pathological case, only a single written chunk\n// would be consumed, and then the rest would wait (un-transformed) until\n// the results of the previous transformed chunk were consumed.\n\n\nmodule.exports = Transform;\n\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_TRANSFORM_ALREADY_TRANSFORMING = _require$codes.ERR_TRANSFORM_ALREADY_TRANSFORMING,\n    ERR_TRANSFORM_WITH_LENGTH_0 = _require$codes.ERR_TRANSFORM_WITH_LENGTH_0;\n\nvar Duplex = __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Transform, Duplex);\n\nfunction afterTransform(er, data) {\n  var ts = this._transformState;\n  ts.transforming = false;\n  var cb = ts.writecb;\n\n  if (cb === null) {\n    return this.emit('error', new ERR_MULTIPLE_CALLBACK());\n  }\n\n  ts.writechunk = null;\n  ts.writecb = null;\n  if (data != null) // single equals check for both `null` and `undefined`\n    this.push(data);\n  cb(er);\n  var rs = this._readableState;\n  rs.reading = false;\n\n  if (rs.needReadable || rs.length < rs.highWaterMark) {\n    this._read(rs.highWaterMark);\n  }\n}\n\nfunction Transform(options) {\n  if (!(this instanceof Transform)) return new Transform(options);\n  Duplex.call(this, options);\n  this._transformState = {\n    afterTransform: afterTransform.bind(this),\n    needTransform: false,\n    transforming: false,\n    writecb: null,\n    writechunk: null,\n    writeencoding: null\n  }; // start out asking for a readable event once data is transformed.\n\n  this._readableState.needReadable = true; // we have implemented the _read method, and done the other things\n  // that Readable wants before the first _read call, so unset the\n  // sync guard flag.\n\n  this._readableState.sync = false;\n\n  if (options) {\n    if (typeof options.transform === 'function') this._transform = options.transform;\n    if (typeof options.flush === 'function') this._flush = options.flush;\n  } // When the writable side finishes, then flush out anything remaining.\n\n\n  this.on('prefinish', prefinish);\n}\n\nfunction prefinish() {\n  var _this = this;\n\n  if (typeof this._flush === 'function' && !this._readableState.destroyed) {\n    this._flush(function (er, data) {\n      done(_this, er, data);\n    });\n  } else {\n    done(this, null, null);\n  }\n}\n\nTransform.prototype.push = function (chunk, encoding) {\n  this._transformState.needTransform = false;\n  return Duplex.prototype.push.call(this, chunk, encoding);\n}; // This is the part where you do stuff!\n// override this function in implementation classes.\n// 'chunk' is an input chunk.\n//\n// Call `push(newChunk)` to pass along transformed output\n// to the readable side.  You may call 'push' zero or more times.\n//\n// Call `cb(err)` when you are done with this chunk.  If you pass\n// an error, then that'll put the hurt on the whole operation.  If you\n// never call cb(), then you'll never get another chunk.\n\n\nTransform.prototype._transform = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_transform()'));\n};\n\nTransform.prototype._write = function (chunk, encoding, cb) {\n  var ts = this._transformState;\n  ts.writecb = cb;\n  ts.writechunk = chunk;\n  ts.writeencoding = encoding;\n\n  if (!ts.transforming) {\n    var rs = this._readableState;\n    if (ts.needTransform || rs.needReadable || rs.length < rs.highWaterMark) this._read(rs.highWaterMark);\n  }\n}; // Doesn't matter what the args are here.\n// _transform does all the work.\n// That we got here means that the readable side wants more data.\n\n\nTransform.prototype._read = function (n) {\n  var ts = this._transformState;\n\n  if (ts.writechunk !== null && !ts.transforming) {\n    ts.transforming = true;\n\n    this._transform(ts.writechunk, ts.writeencoding, ts.afterTransform);\n  } else {\n    // mark that we need a transform, so that any data that comes in\n    // will get processed, now that we've asked for it.\n    ts.needTransform = true;\n  }\n};\n\nTransform.prototype._destroy = function (err, cb) {\n  Duplex.prototype._destroy.call(this, err, function (err2) {\n    cb(err2);\n  });\n};\n\nfunction done(stream, er, data) {\n  if (er) return stream.emit('error', er);\n  if (data != null) // single equals check for both `null` and `undefined`\n    stream.push(data); // TODO(BridgeAR): Write a test for these two error cases\n  // if there's nothing in the write buffer, then that means\n  // that nothing more will ever be provided\n\n  if (stream._writableState.length) throw new ERR_TRANSFORM_WITH_LENGTH_0();\n  if (stream._transformState.transforming) throw new ERR_TRANSFORM_ALREADY_TRANSFORMING();\n  return stream.push(null);\n}\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/_stream_transform.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/_stream_writable.js":
/*!**************************************************************!*\
  !*** ./node_modules/readable-stream/lib/_stream_writable.js ***!
  \**************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Copyright Joyent, Inc. and other Node contributors.\n//\n// Permission is hereby granted, free of charge, to any person obtaining a\n// copy of this software and associated documentation files (the\n// \"Software\"), to deal in the Software without restriction, including\n// without limitation the rights to use, copy, modify, merge, publish,\n// distribute, sublicense, and/or sell copies of the Software, and to permit\n// persons to whom the Software is furnished to do so, subject to the\n// following conditions:\n//\n// The above copyright notice and this permission notice shall be included\n// in all copies or substantial portions of the Software.\n//\n// THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS\n// OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF\n// MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN\n// NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM,\n// DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR\n// OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE\n// USE OR OTHER DEALINGS IN THE SOFTWARE.\n// A bit simpler than readable streams.\n// Implement an async ._write(chunk, encoding, cb), and it'll handle all\n// the drain event emission and buffering.\n\n\nmodule.exports = Writable;\n/* <replacement> */\n\nfunction WriteReq(chunk, encoding, cb) {\n  this.chunk = chunk;\n  this.encoding = encoding;\n  this.callback = cb;\n  this.next = null;\n} // It seems a linked list but it is not\n// there will be only 2 of these for each stream\n\n\nfunction CorkedRequest(state) {\n  var _this = this;\n\n  this.next = null;\n  this.entry = null;\n\n  this.finish = function () {\n    onCorkedFinish(_this, state);\n  };\n}\n/* </replacement> */\n\n/*<replacement>*/\n\n\nvar Duplex;\n/*</replacement>*/\n\nWritable.WritableState = WritableState;\n/*<replacement>*/\n\nvar internalUtil = {\n  deprecate: __webpack_require__(/*! util-deprecate */ \"./node_modules/util-deprecate/browser.js\")\n};\n/*</replacement>*/\n\n/*<replacement>*/\n\nvar Stream = __webpack_require__(/*! ./internal/streams/stream */ \"./node_modules/readable-stream/lib/internal/streams/stream-browser.js\");\n/*</replacement>*/\n\n\nvar Buffer = Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }());\n\nvar OurUint8Array = __webpack_require__.g.Uint8Array || function () {};\n\nfunction _uint8ArrayToBuffer(chunk) {\n  return Buffer.from(chunk);\n}\n\nfunction _isUint8Array(obj) {\n  return Buffer.isBuffer(obj) || obj instanceof OurUint8Array;\n}\n\nvar destroyImpl = __webpack_require__(/*! ./internal/streams/destroy */ \"./node_modules/readable-stream/lib/internal/streams/destroy.js\");\n\nvar _require = __webpack_require__(/*! ./internal/streams/state */ \"./node_modules/readable-stream/lib/internal/streams/state.js\"),\n    getHighWaterMark = _require.getHighWaterMark;\n\nvar _require$codes = (__webpack_require__(/*! ../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_INVALID_ARG_TYPE = _require$codes.ERR_INVALID_ARG_TYPE,\n    ERR_METHOD_NOT_IMPLEMENTED = _require$codes.ERR_METHOD_NOT_IMPLEMENTED,\n    ERR_MULTIPLE_CALLBACK = _require$codes.ERR_MULTIPLE_CALLBACK,\n    ERR_STREAM_CANNOT_PIPE = _require$codes.ERR_STREAM_CANNOT_PIPE,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED,\n    ERR_STREAM_NULL_VALUES = _require$codes.ERR_STREAM_NULL_VALUES,\n    ERR_STREAM_WRITE_AFTER_END = _require$codes.ERR_STREAM_WRITE_AFTER_END,\n    ERR_UNKNOWN_ENCODING = _require$codes.ERR_UNKNOWN_ENCODING;\n\nvar errorOrDestroy = destroyImpl.errorOrDestroy;\n\n__webpack_require__(/*! inherits */ \"./node_modules/inherits/inherits_browser.js\")(Writable, Stream);\n\nfunction nop() {}\n\nfunction WritableState(options, stream, isDuplex) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\n  options = options || {}; // Duplex streams are both readable and writable, but share\n  // the same options object.\n  // However, some cases require setting options to different\n  // values for the readable and the writable sides of the duplex stream,\n  // e.g. options.readableObjectMode vs. options.writableObjectMode, etc.\n\n  if (typeof isDuplex !== 'boolean') isDuplex = stream instanceof Duplex; // object stream flag to indicate whether or not this stream\n  // contains buffers or objects.\n\n  this.objectMode = !!options.objectMode;\n  if (isDuplex) this.objectMode = this.objectMode || !!options.writableObjectMode; // the point at which write() starts returning false\n  // Note: 0 is a valid value, means that we always return false if\n  // the entire buffer is not flushed immediately on write()\n\n  this.highWaterMark = getHighWaterMark(this, options, 'writableHighWaterMark', isDuplex); // if _final has been called\n\n  this.finalCalled = false; // drain event flag.\n\n  this.needDrain = false; // at the start of calling end()\n\n  this.ending = false; // when end() has been called, and returned\n\n  this.ended = false; // when 'finish' is emitted\n\n  this.finished = false; // has it been destroyed\n\n  this.destroyed = false; // should we decode strings into buffers before passing to _write?\n  // this is here so that some node-core streams can optimize string\n  // handling at a lower level.\n\n  var noDecode = options.decodeStrings === false;\n  this.decodeStrings = !noDecode; // Crypto is kind of old and crusty.  Historically, its default string\n  // encoding is 'binary' so we have to make this configurable.\n  // Everything else in the universe uses 'utf8', though.\n\n  this.defaultEncoding = options.defaultEncoding || 'utf8'; // not an actual buffer we keep track of, but a measurement\n  // of how much we're waiting to get pushed to some underlying\n  // socket or file.\n\n  this.length = 0; // a flag to see when we're in the middle of a write.\n\n  this.writing = false; // when true all writes will be buffered until .uncork() call\n\n  this.corked = 0; // a flag to be able to tell if the onwrite cb is called immediately,\n  // or on a later tick.  We set this to true at first, because any\n  // actions that shouldn't happen until \"later\" should generally also\n  // not happen before the first write call.\n\n  this.sync = true; // a flag to know if we're processing previously buffered items, which\n  // may call the _write() callback in the same tick, so that we don't\n  // end up in an overlapped onwrite situation.\n\n  this.bufferProcessing = false; // the callback that's passed to _write(chunk,cb)\n\n  this.onwrite = function (er) {\n    onwrite(stream, er);\n  }; // the callback that the user supplies to write(chunk,encoding,cb)\n\n\n  this.writecb = null; // the amount that is being written when _write is called.\n\n  this.writelen = 0;\n  this.bufferedRequest = null;\n  this.lastBufferedRequest = null; // number of pending user-supplied write callbacks\n  // this must be 0 before 'finish' can be emitted\n\n  this.pendingcb = 0; // emit prefinish if the only thing we're waiting for is _write cbs\n  // This is relevant for synchronous Transform streams\n\n  this.prefinished = false; // True if the error was already emitted and should not be thrown again\n\n  this.errorEmitted = false; // Should close be emitted on destroy. Defaults to true.\n\n  this.emitClose = options.emitClose !== false; // Should .destroy() be called after 'finish' (and potentially 'end')\n\n  this.autoDestroy = !!options.autoDestroy; // count buffered requests\n\n  this.bufferedRequestCount = 0; // allocate the first CorkedRequest, there is always\n  // one allocated and free to use, and we maintain at most two\n\n  this.corkedRequestsFree = new CorkedRequest(this);\n}\n\nWritableState.prototype.getBuffer = function getBuffer() {\n  var current = this.bufferedRequest;\n  var out = [];\n\n  while (current) {\n    out.push(current);\n    current = current.next;\n  }\n\n  return out;\n};\n\n(function () {\n  try {\n    Object.defineProperty(WritableState.prototype, 'buffer', {\n      get: internalUtil.deprecate(function writableStateBufferGetter() {\n        return this.getBuffer();\n      }, '_writableState.buffer is deprecated. Use _writableState.getBuffer ' + 'instead.', 'DEP0003')\n    });\n  } catch (_) {}\n})(); // Test _writableState for inheritance to account for Duplex streams,\n// whose prototype chain only points to Readable.\n\n\nvar realHasInstance;\n\nif (typeof Symbol === 'function' && Symbol.hasInstance && typeof Function.prototype[Symbol.hasInstance] === 'function') {\n  realHasInstance = Function.prototype[Symbol.hasInstance];\n  Object.defineProperty(Writable, Symbol.hasInstance, {\n    value: function value(object) {\n      if (realHasInstance.call(this, object)) return true;\n      if (this !== Writable) return false;\n      return object && object._writableState instanceof WritableState;\n    }\n  });\n} else {\n  realHasInstance = function realHasInstance(object) {\n    return object instanceof this;\n  };\n}\n\nfunction Writable(options) {\n  Duplex = Duplex || __webpack_require__(/*! ./_stream_duplex */ \"./node_modules/readable-stream/lib/_stream_duplex.js\"); // Writable ctor is applied to Duplexes, too.\n  // `realHasInstance` is necessary because using plain `instanceof`\n  // would return false, as no `_writableState` property is attached.\n  // Trying to use the custom `instanceof` for Writable here will also break the\n  // Node.js LazyTransform implementation, which has a non-trivial getter for\n  // `_writableState` that would lead to infinite recursion.\n  // Checking for a Stream.Duplex instance is faster here instead of inside\n  // the WritableState constructor, at least with V8 6.5\n\n  var isDuplex = this instanceof Duplex;\n  if (!isDuplex && !realHasInstance.call(Writable, this)) return new Writable(options);\n  this._writableState = new WritableState(options, this, isDuplex); // legacy.\n\n  this.writable = true;\n\n  if (options) {\n    if (typeof options.write === 'function') this._write = options.write;\n    if (typeof options.writev === 'function') this._writev = options.writev;\n    if (typeof options.destroy === 'function') this._destroy = options.destroy;\n    if (typeof options.final === 'function') this._final = options.final;\n  }\n\n  Stream.call(this);\n} // Otherwise people can pipe Writable streams, which is just wrong.\n\n\nWritable.prototype.pipe = function () {\n  errorOrDestroy(this, new ERR_STREAM_CANNOT_PIPE());\n};\n\nfunction writeAfterEnd(stream, cb) {\n  var er = new ERR_STREAM_WRITE_AFTER_END(); // TODO: defer error events consistently everywhere, not just the cb\n\n  errorOrDestroy(stream, er);\n  process.nextTick(cb, er);\n} // Checks that a user-supplied chunk is valid, especially for the particular\n// mode the stream is in. Currently this means that `null` is never accepted\n// and undefined/non-string values are only allowed in object mode.\n\n\nfunction validChunk(stream, state, chunk, cb) {\n  var er;\n\n  if (chunk === null) {\n    er = new ERR_STREAM_NULL_VALUES();\n  } else if (typeof chunk !== 'string' && !state.objectMode) {\n    er = new ERR_INVALID_ARG_TYPE('chunk', ['string', 'Buffer'], chunk);\n  }\n\n  if (er) {\n    errorOrDestroy(stream, er);\n    process.nextTick(cb, er);\n    return false;\n  }\n\n  return true;\n}\n\nWritable.prototype.write = function (chunk, encoding, cb) {\n  var state = this._writableState;\n  var ret = false;\n\n  var isBuf = !state.objectMode && _isUint8Array(chunk);\n\n  if (isBuf && !Buffer.isBuffer(chunk)) {\n    chunk = _uint8ArrayToBuffer(chunk);\n  }\n\n  if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (isBuf) encoding = 'buffer';else if (!encoding) encoding = state.defaultEncoding;\n  if (typeof cb !== 'function') cb = nop;\n  if (state.ending) writeAfterEnd(this, cb);else if (isBuf || validChunk(this, state, chunk, cb)) {\n    state.pendingcb++;\n    ret = writeOrBuffer(this, state, isBuf, chunk, encoding, cb);\n  }\n  return ret;\n};\n\nWritable.prototype.cork = function () {\n  this._writableState.corked++;\n};\n\nWritable.prototype.uncork = function () {\n  var state = this._writableState;\n\n  if (state.corked) {\n    state.corked--;\n    if (!state.writing && !state.corked && !state.bufferProcessing && state.bufferedRequest) clearBuffer(this, state);\n  }\n};\n\nWritable.prototype.setDefaultEncoding = function setDefaultEncoding(encoding) {\n  // node::ParseEncoding() requires lower case.\n  if (typeof encoding === 'string') encoding = encoding.toLowerCase();\n  if (!(['hex', 'utf8', 'utf-8', 'ascii', 'binary', 'base64', 'ucs2', 'ucs-2', 'utf16le', 'utf-16le', 'raw'].indexOf((encoding + '').toLowerCase()) > -1)) throw new ERR_UNKNOWN_ENCODING(encoding);\n  this._writableState.defaultEncoding = encoding;\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableBuffer', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState && this._writableState.getBuffer();\n  }\n});\n\nfunction decodeChunk(state, chunk, encoding) {\n  if (!state.objectMode && state.decodeStrings !== false && typeof chunk === 'string') {\n    chunk = Buffer.from(chunk, encoding);\n  }\n\n  return chunk;\n}\n\nObject.defineProperty(Writable.prototype, 'writableHighWaterMark', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.highWaterMark;\n  }\n}); // if we're already writing something, then just put this\n// in the queue, and wait our turn.  Otherwise, call _write\n// If we return false, then we need a drain event, so set that flag.\n\nfunction writeOrBuffer(stream, state, isBuf, chunk, encoding, cb) {\n  if (!isBuf) {\n    var newChunk = decodeChunk(state, chunk, encoding);\n\n    if (chunk !== newChunk) {\n      isBuf = true;\n      encoding = 'buffer';\n      chunk = newChunk;\n    }\n  }\n\n  var len = state.objectMode ? 1 : chunk.length;\n  state.length += len;\n  var ret = state.length < state.highWaterMark; // we must ensure that previous needDrain will not be reset to false.\n\n  if (!ret) state.needDrain = true;\n\n  if (state.writing || state.corked) {\n    var last = state.lastBufferedRequest;\n    state.lastBufferedRequest = {\n      chunk: chunk,\n      encoding: encoding,\n      isBuf: isBuf,\n      callback: cb,\n      next: null\n    };\n\n    if (last) {\n      last.next = state.lastBufferedRequest;\n    } else {\n      state.bufferedRequest = state.lastBufferedRequest;\n    }\n\n    state.bufferedRequestCount += 1;\n  } else {\n    doWrite(stream, state, false, len, chunk, encoding, cb);\n  }\n\n  return ret;\n}\n\nfunction doWrite(stream, state, writev, len, chunk, encoding, cb) {\n  state.writelen = len;\n  state.writecb = cb;\n  state.writing = true;\n  state.sync = true;\n  if (state.destroyed) state.onwrite(new ERR_STREAM_DESTROYED('write'));else if (writev) stream._writev(chunk, state.onwrite);else stream._write(chunk, encoding, state.onwrite);\n  state.sync = false;\n}\n\nfunction onwriteError(stream, state, sync, er, cb) {\n  --state.pendingcb;\n\n  if (sync) {\n    // defer the callback if we are being called synchronously\n    // to avoid piling up things on the stack\n    process.nextTick(cb, er); // this can emit finish, and it will always happen\n    // after error\n\n    process.nextTick(finishMaybe, stream, state);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er);\n  } else {\n    // the caller expect this to happen before if\n    // it is async\n    cb(er);\n    stream._writableState.errorEmitted = true;\n    errorOrDestroy(stream, er); // this can emit finish, but finish must\n    // always follow error\n\n    finishMaybe(stream, state);\n  }\n}\n\nfunction onwriteStateUpdate(state) {\n  state.writing = false;\n  state.writecb = null;\n  state.length -= state.writelen;\n  state.writelen = 0;\n}\n\nfunction onwrite(stream, er) {\n  var state = stream._writableState;\n  var sync = state.sync;\n  var cb = state.writecb;\n  if (typeof cb !== 'function') throw new ERR_MULTIPLE_CALLBACK();\n  onwriteStateUpdate(state);\n  if (er) onwriteError(stream, state, sync, er, cb);else {\n    // Check if we're actually ready to finish, but don't emit yet\n    var finished = needFinish(state) || stream.destroyed;\n\n    if (!finished && !state.corked && !state.bufferProcessing && state.bufferedRequest) {\n      clearBuffer(stream, state);\n    }\n\n    if (sync) {\n      process.nextTick(afterWrite, stream, state, finished, cb);\n    } else {\n      afterWrite(stream, state, finished, cb);\n    }\n  }\n}\n\nfunction afterWrite(stream, state, finished, cb) {\n  if (!finished) onwriteDrain(stream, state);\n  state.pendingcb--;\n  cb();\n  finishMaybe(stream, state);\n} // Must force callback to be called on nextTick, so that we don't\n// emit 'drain' before the write() consumer gets the 'false' return\n// value, and has a chance to attach a 'drain' listener.\n\n\nfunction onwriteDrain(stream, state) {\n  if (state.length === 0 && state.needDrain) {\n    state.needDrain = false;\n    stream.emit('drain');\n  }\n} // if there's something in the buffer waiting, then process it\n\n\nfunction clearBuffer(stream, state) {\n  state.bufferProcessing = true;\n  var entry = state.bufferedRequest;\n\n  if (stream._writev && entry && entry.next) {\n    // Fast case, write everything using _writev()\n    var l = state.bufferedRequestCount;\n    var buffer = new Array(l);\n    var holder = state.corkedRequestsFree;\n    holder.entry = entry;\n    var count = 0;\n    var allBuffers = true;\n\n    while (entry) {\n      buffer[count] = entry;\n      if (!entry.isBuf) allBuffers = false;\n      entry = entry.next;\n      count += 1;\n    }\n\n    buffer.allBuffers = allBuffers;\n    doWrite(stream, state, true, state.length, buffer, '', holder.finish); // doWrite is almost always async, defer these to save a bit of time\n    // as the hot path ends with doWrite\n\n    state.pendingcb++;\n    state.lastBufferedRequest = null;\n\n    if (holder.next) {\n      state.corkedRequestsFree = holder.next;\n      holder.next = null;\n    } else {\n      state.corkedRequestsFree = new CorkedRequest(state);\n    }\n\n    state.bufferedRequestCount = 0;\n  } else {\n    // Slow case, write chunks one-by-one\n    while (entry) {\n      var chunk = entry.chunk;\n      var encoding = entry.encoding;\n      var cb = entry.callback;\n      var len = state.objectMode ? 1 : chunk.length;\n      doWrite(stream, state, false, len, chunk, encoding, cb);\n      entry = entry.next;\n      state.bufferedRequestCount--; // if we didn't call the onwrite immediately, then\n      // it means that we need to wait until it does.\n      // also, that means that the chunk and cb are currently\n      // being processed, so move the buffer counter past them.\n\n      if (state.writing) {\n        break;\n      }\n    }\n\n    if (entry === null) state.lastBufferedRequest = null;\n  }\n\n  state.bufferedRequest = entry;\n  state.bufferProcessing = false;\n}\n\nWritable.prototype._write = function (chunk, encoding, cb) {\n  cb(new ERR_METHOD_NOT_IMPLEMENTED('_write()'));\n};\n\nWritable.prototype._writev = null;\n\nWritable.prototype.end = function (chunk, encoding, cb) {\n  var state = this._writableState;\n\n  if (typeof chunk === 'function') {\n    cb = chunk;\n    chunk = null;\n    encoding = null;\n  } else if (typeof encoding === 'function') {\n    cb = encoding;\n    encoding = null;\n  }\n\n  if (chunk !== null && chunk !== undefined) this.write(chunk, encoding); // .end() fully uncorks\n\n  if (state.corked) {\n    state.corked = 1;\n    this.uncork();\n  } // ignore unnecessary end() calls.\n\n\n  if (!state.ending) endWritable(this, state, cb);\n  return this;\n};\n\nObject.defineProperty(Writable.prototype, 'writableLength', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    return this._writableState.length;\n  }\n});\n\nfunction needFinish(state) {\n  return state.ending && state.length === 0 && state.bufferedRequest === null && !state.finished && !state.writing;\n}\n\nfunction callFinal(stream, state) {\n  stream._final(function (err) {\n    state.pendingcb--;\n\n    if (err) {\n      errorOrDestroy(stream, err);\n    }\n\n    state.prefinished = true;\n    stream.emit('prefinish');\n    finishMaybe(stream, state);\n  });\n}\n\nfunction prefinish(stream, state) {\n  if (!state.prefinished && !state.finalCalled) {\n    if (typeof stream._final === 'function' && !state.destroyed) {\n      state.pendingcb++;\n      state.finalCalled = true;\n      process.nextTick(callFinal, stream, state);\n    } else {\n      state.prefinished = true;\n      stream.emit('prefinish');\n    }\n  }\n}\n\nfunction finishMaybe(stream, state) {\n  var need = needFinish(state);\n\n  if (need) {\n    prefinish(stream, state);\n\n    if (state.pendingcb === 0) {\n      state.finished = true;\n      stream.emit('finish');\n\n      if (state.autoDestroy) {\n        // In case of duplex streams we need a way to detect\n        // if the readable side is ready for autoDestroy as well\n        var rState = stream._readableState;\n\n        if (!rState || rState.autoDestroy && rState.endEmitted) {\n          stream.destroy();\n        }\n      }\n    }\n  }\n\n  return need;\n}\n\nfunction endWritable(stream, state, cb) {\n  state.ending = true;\n  finishMaybe(stream, state);\n\n  if (cb) {\n    if (state.finished) process.nextTick(cb);else stream.once('finish', cb);\n  }\n\n  state.ended = true;\n  stream.writable = false;\n}\n\nfunction onCorkedFinish(corkReq, state, err) {\n  var entry = corkReq.entry;\n  corkReq.entry = null;\n\n  while (entry) {\n    var cb = entry.callback;\n    state.pendingcb--;\n    cb(err);\n    entry = entry.next;\n  } // reuse the free corkReq.\n\n\n  state.corkedRequestsFree.next = corkReq;\n}\n\nObject.defineProperty(Writable.prototype, 'destroyed', {\n  // making it explicit this property is not enumerable\n  // because otherwise some prototype manipulation in\n  // userland will fail\n  enumerable: false,\n  get: function get() {\n    if (this._writableState === undefined) {\n      return false;\n    }\n\n    return this._writableState.destroyed;\n  },\n  set: function set(value) {\n    // we ignore the value if the stream\n    // has not been initialized yet\n    if (!this._writableState) {\n      return;\n    } // backward compatibility, the user is explicitly\n    // managing destroyed\n\n\n    this._writableState.destroyed = value;\n  }\n});\nWritable.prototype.destroy = destroyImpl.destroy;\nWritable.prototype._undestroy = destroyImpl.undestroy;\n\nWritable.prototype._destroy = function (err, cb) {\n  cb(err);\n};\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/_stream_writable.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/async_iterator.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/async_iterator.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar _Object$setPrototypeO;\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nvar finished = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n\nvar kLastResolve = Symbol('lastResolve');\nvar kLastReject = Symbol('lastReject');\nvar kError = Symbol('error');\nvar kEnded = Symbol('ended');\nvar kLastPromise = Symbol('lastPromise');\nvar kHandlePromise = Symbol('handlePromise');\nvar kStream = Symbol('stream');\n\nfunction createIterResult(value, done) {\n  return {\n    value: value,\n    done: done\n  };\n}\n\nfunction readAndResolve(iter) {\n  var resolve = iter[kLastResolve];\n\n  if (resolve !== null) {\n    var data = iter[kStream].read(); // we defer if data is null\n    // we can be expecting either 'end' or\n    // 'error'\n\n    if (data !== null) {\n      iter[kLastPromise] = null;\n      iter[kLastResolve] = null;\n      iter[kLastReject] = null;\n      resolve(createIterResult(data, false));\n    }\n  }\n}\n\nfunction onReadable(iter) {\n  // we wait for the next tick, because it might\n  // emit an error with process.nextTick\n  process.nextTick(readAndResolve, iter);\n}\n\nfunction wrapForNext(lastPromise, iter) {\n  return function (resolve, reject) {\n    lastPromise.then(function () {\n      if (iter[kEnded]) {\n        resolve(createIterResult(undefined, true));\n        return;\n      }\n\n      iter[kHandlePromise](resolve, reject);\n    }, reject);\n  };\n}\n\nvar AsyncIteratorPrototype = Object.getPrototypeOf(function () {});\nvar ReadableStreamAsyncIteratorPrototype = Object.setPrototypeOf((_Object$setPrototypeO = {\n  get stream() {\n    return this[kStream];\n  },\n\n  next: function next() {\n    var _this = this;\n\n    // if we have detected an error in the meanwhile\n    // reject straight away\n    var error = this[kError];\n\n    if (error !== null) {\n      return Promise.reject(error);\n    }\n\n    if (this[kEnded]) {\n      return Promise.resolve(createIterResult(undefined, true));\n    }\n\n    if (this[kStream].destroyed) {\n      // We need to defer via nextTick because if .destroy(err) is\n      // called, the error will be emitted via nextTick, and\n      // we cannot guarantee that there is no error lingering around\n      // waiting to be emitted.\n      return new Promise(function (resolve, reject) {\n        process.nextTick(function () {\n          if (_this[kError]) {\n            reject(_this[kError]);\n          } else {\n            resolve(createIterResult(undefined, true));\n          }\n        });\n      });\n    } // if we have multiple next() calls\n    // we will wait for the previous Promise to finish\n    // this logic is optimized to support for await loops,\n    // where next() is only called once at a time\n\n\n    var lastPromise = this[kLastPromise];\n    var promise;\n\n    if (lastPromise) {\n      promise = new Promise(wrapForNext(lastPromise, this));\n    } else {\n      // fast path needed to support multiple this.push()\n      // without triggering the next() queue\n      var data = this[kStream].read();\n\n      if (data !== null) {\n        return Promise.resolve(createIterResult(data, false));\n      }\n\n      promise = new Promise(this[kHandlePromise]);\n    }\n\n    this[kLastPromise] = promise;\n    return promise;\n  }\n}, _defineProperty(_Object$setPrototypeO, Symbol.asyncIterator, function () {\n  return this;\n}), _defineProperty(_Object$setPrototypeO, \"return\", function _return() {\n  var _this2 = this;\n\n  // destroy(err, cb) is a private API\n  // we can guarantee we have that here, because we control the\n  // Readable class this is attached to\n  return new Promise(function (resolve, reject) {\n    _this2[kStream].destroy(null, function (err) {\n      if (err) {\n        reject(err);\n        return;\n      }\n\n      resolve(createIterResult(undefined, true));\n    });\n  });\n}), _Object$setPrototypeO), AsyncIteratorPrototype);\n\nvar createReadableStreamAsyncIterator = function createReadableStreamAsyncIterator(stream) {\n  var _Object$create;\n\n  var iterator = Object.create(ReadableStreamAsyncIteratorPrototype, (_Object$create = {}, _defineProperty(_Object$create, kStream, {\n    value: stream,\n    writable: true\n  }), _defineProperty(_Object$create, kLastResolve, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kLastReject, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kError, {\n    value: null,\n    writable: true\n  }), _defineProperty(_Object$create, kEnded, {\n    value: stream._readableState.endEmitted,\n    writable: true\n  }), _defineProperty(_Object$create, kHandlePromise, {\n    value: function value(resolve, reject) {\n      var data = iterator[kStream].read();\n\n      if (data) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        resolve(createIterResult(data, false));\n      } else {\n        iterator[kLastResolve] = resolve;\n        iterator[kLastReject] = reject;\n      }\n    },\n    writable: true\n  }), _Object$create));\n  iterator[kLastPromise] = null;\n  finished(stream, function (err) {\n    if (err && err.code !== 'ERR_STREAM_PREMATURE_CLOSE') {\n      var reject = iterator[kLastReject]; // reject if we are waiting for data in the Promise\n      // returned by next() and store the error\n\n      if (reject !== null) {\n        iterator[kLastPromise] = null;\n        iterator[kLastResolve] = null;\n        iterator[kLastReject] = null;\n        reject(err);\n      }\n\n      iterator[kError] = err;\n      return;\n    }\n\n    var resolve = iterator[kLastResolve];\n\n    if (resolve !== null) {\n      iterator[kLastPromise] = null;\n      iterator[kLastResolve] = null;\n      iterator[kLastReject] = null;\n      resolve(createIterResult(undefined, true));\n    }\n\n    iterator[kEnded] = true;\n  });\n  stream.on('readable', onReadable.bind(null, iterator));\n  return iterator;\n};\n\nmodule.exports = createReadableStreamAsyncIterator;\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/async_iterator.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/buffer_list.js":
/*!**************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/buffer_list.js ***!
  \**************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nfunction ownKeys(object, enumerableOnly) { var keys = Object.keys(object); if (Object.getOwnPropertySymbols) { var symbols = Object.getOwnPropertySymbols(object); if (enumerableOnly) symbols = symbols.filter(function (sym) { return Object.getOwnPropertyDescriptor(object, sym).enumerable; }); keys.push.apply(keys, symbols); } return keys; }\n\nfunction _objectSpread(target) { for (var i = 1; i < arguments.length; i++) { var source = arguments[i] != null ? arguments[i] : {}; if (i % 2) { ownKeys(Object(source), true).forEach(function (key) { _defineProperty(target, key, source[key]); }); } else if (Object.getOwnPropertyDescriptors) { Object.defineProperties(target, Object.getOwnPropertyDescriptors(source)); } else { ownKeys(Object(source)).forEach(function (key) { Object.defineProperty(target, key, Object.getOwnPropertyDescriptor(source, key)); }); } } return target; }\n\nfunction _defineProperty(obj, key, value) { if (key in obj) { Object.defineProperty(obj, key, { value: value, enumerable: true, configurable: true, writable: true }); } else { obj[key] = value; } return obj; }\n\nfunction _classCallCheck(instance, Constructor) { if (!(instance instanceof Constructor)) { throw new TypeError(\"Cannot call a class as a function\"); } }\n\nfunction _defineProperties(target, props) { for (var i = 0; i < props.length; i++) { var descriptor = props[i]; descriptor.enumerable = descriptor.enumerable || false; descriptor.configurable = true; if (\"value\" in descriptor) descriptor.writable = true; Object.defineProperty(target, descriptor.key, descriptor); } }\n\nfunction _createClass(Constructor, protoProps, staticProps) { if (protoProps) _defineProperties(Constructor.prototype, protoProps); if (staticProps) _defineProperties(Constructor, staticProps); return Constructor; }\n\nvar _require = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'buffer'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }())),\n    Buffer = _require.Buffer;\n\nvar _require2 = __webpack_require__(/*! util */ \"?ed1b\"),\n    inspect = _require2.inspect;\n\nvar custom = inspect && inspect.custom || 'inspect';\n\nfunction copyBuffer(src, target, offset) {\n  Buffer.prototype.copy.call(src, target, offset);\n}\n\nmodule.exports =\n/*#__PURE__*/\nfunction () {\n  function BufferList() {\n    _classCallCheck(this, BufferList);\n\n    this.head = null;\n    this.tail = null;\n    this.length = 0;\n  }\n\n  _createClass(BufferList, [{\n    key: \"push\",\n    value: function push(v) {\n      var entry = {\n        data: v,\n        next: null\n      };\n      if (this.length > 0) this.tail.next = entry;else this.head = entry;\n      this.tail = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"unshift\",\n    value: function unshift(v) {\n      var entry = {\n        data: v,\n        next: this.head\n      };\n      if (this.length === 0) this.tail = entry;\n      this.head = entry;\n      ++this.length;\n    }\n  }, {\n    key: \"shift\",\n    value: function shift() {\n      if (this.length === 0) return;\n      var ret = this.head.data;\n      if (this.length === 1) this.head = this.tail = null;else this.head = this.head.next;\n      --this.length;\n      return ret;\n    }\n  }, {\n    key: \"clear\",\n    value: function clear() {\n      this.head = this.tail = null;\n      this.length = 0;\n    }\n  }, {\n    key: \"join\",\n    value: function join(s) {\n      if (this.length === 0) return '';\n      var p = this.head;\n      var ret = '' + p.data;\n\n      while (p = p.next) {\n        ret += s + p.data;\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"concat\",\n    value: function concat(n) {\n      if (this.length === 0) return Buffer.alloc(0);\n      var ret = Buffer.allocUnsafe(n >>> 0);\n      var p = this.head;\n      var i = 0;\n\n      while (p) {\n        copyBuffer(p.data, ret, i);\n        i += p.data.length;\n        p = p.next;\n      }\n\n      return ret;\n    } // Consumes a specified amount of bytes or characters from the buffered data.\n\n  }, {\n    key: \"consume\",\n    value: function consume(n, hasStrings) {\n      var ret;\n\n      if (n < this.head.data.length) {\n        // `slice` is the same for buffers and strings.\n        ret = this.head.data.slice(0, n);\n        this.head.data = this.head.data.slice(n);\n      } else if (n === this.head.data.length) {\n        // First chunk is a perfect match.\n        ret = this.shift();\n      } else {\n        // Result spans more than one buffer.\n        ret = hasStrings ? this._getString(n) : this._getBuffer(n);\n      }\n\n      return ret;\n    }\n  }, {\n    key: \"first\",\n    value: function first() {\n      return this.head.data;\n    } // Consumes a specified amount of characters from the buffered data.\n\n  }, {\n    key: \"_getString\",\n    value: function _getString(n) {\n      var p = this.head;\n      var c = 1;\n      var ret = p.data;\n      n -= ret.length;\n\n      while (p = p.next) {\n        var str = p.data;\n        var nb = n > str.length ? str.length : n;\n        if (nb === str.length) ret += str;else ret += str.slice(0, n);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === str.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = str.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Consumes a specified amount of bytes from the buffered data.\n\n  }, {\n    key: \"_getBuffer\",\n    value: function _getBuffer(n) {\n      var ret = Buffer.allocUnsafe(n);\n      var p = this.head;\n      var c = 1;\n      p.data.copy(ret);\n      n -= p.data.length;\n\n      while (p = p.next) {\n        var buf = p.data;\n        var nb = n > buf.length ? buf.length : n;\n        buf.copy(ret, ret.length - n, 0, nb);\n        n -= nb;\n\n        if (n === 0) {\n          if (nb === buf.length) {\n            ++c;\n            if (p.next) this.head = p.next;else this.head = this.tail = null;\n          } else {\n            this.head = p;\n            p.data = buf.slice(nb);\n          }\n\n          break;\n        }\n\n        ++c;\n      }\n\n      this.length -= c;\n      return ret;\n    } // Make sure the linked list only shows the minimal necessary information.\n\n  }, {\n    key: custom,\n    value: function value(_, options) {\n      return inspect(this, _objectSpread({}, options, {\n        // Only inspect one level.\n        depth: 0,\n        // It should not recurse.\n        customInspect: false\n      }));\n    }\n  }]);\n\n  return BufferList;\n}();\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/buffer_list.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/destroy.js":
/*!**********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/destroy.js ***!
  \**********************************************************************/
/***/ ((module) => {

"use strict";
eval(" // undocumented cb() API, needed for core, not for public API\n\nfunction destroy(err, cb) {\n  var _this = this;\n\n  var readableDestroyed = this._readableState && this._readableState.destroyed;\n  var writableDestroyed = this._writableState && this._writableState.destroyed;\n\n  if (readableDestroyed || writableDestroyed) {\n    if (cb) {\n      cb(err);\n    } else if (err) {\n      if (!this._writableState) {\n        process.nextTick(emitErrorNT, this, err);\n      } else if (!this._writableState.errorEmitted) {\n        this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorNT, this, err);\n      }\n    }\n\n    return this;\n  } // we set destroyed to true before firing error callbacks in order\n  // to make it re-entrance safe in case destroy() is called within callbacks\n\n\n  if (this._readableState) {\n    this._readableState.destroyed = true;\n  } // if this is a duplex stream mark the writable part as destroyed as well\n\n\n  if (this._writableState) {\n    this._writableState.destroyed = true;\n  }\n\n  this._destroy(err || null, function (err) {\n    if (!cb && err) {\n      if (!_this._writableState) {\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else if (!_this._writableState.errorEmitted) {\n        _this._writableState.errorEmitted = true;\n        process.nextTick(emitErrorAndCloseNT, _this, err);\n      } else {\n        process.nextTick(emitCloseNT, _this);\n      }\n    } else if (cb) {\n      process.nextTick(emitCloseNT, _this);\n      cb(err);\n    } else {\n      process.nextTick(emitCloseNT, _this);\n    }\n  });\n\n  return this;\n}\n\nfunction emitErrorAndCloseNT(self, err) {\n  emitErrorNT(self, err);\n  emitCloseNT(self);\n}\n\nfunction emitCloseNT(self) {\n  if (self._writableState && !self._writableState.emitClose) return;\n  if (self._readableState && !self._readableState.emitClose) return;\n  self.emit('close');\n}\n\nfunction undestroy() {\n  if (this._readableState) {\n    this._readableState.destroyed = false;\n    this._readableState.reading = false;\n    this._readableState.ended = false;\n    this._readableState.endEmitted = false;\n  }\n\n  if (this._writableState) {\n    this._writableState.destroyed = false;\n    this._writableState.ended = false;\n    this._writableState.ending = false;\n    this._writableState.finalCalled = false;\n    this._writableState.prefinished = false;\n    this._writableState.finished = false;\n    this._writableState.errorEmitted = false;\n  }\n}\n\nfunction emitErrorNT(self, err) {\n  self.emit('error', err);\n}\n\nfunction errorOrDestroy(stream, err) {\n  // We have tests that rely on errors being emitted\n  // in the same tick, so changing this is semver major.\n  // For now when you opt-in to autoDestroy we allow\n  // the error to be emitted nextTick. In a future\n  // semver major update we should change the default to this.\n  var rState = stream._readableState;\n  var wState = stream._writableState;\n  if (rState && rState.autoDestroy || wState && wState.autoDestroy) stream.destroy(err);else stream.emit('error', err);\n}\n\nmodule.exports = {\n  destroy: destroy,\n  undestroy: undestroy,\n  errorOrDestroy: errorOrDestroy\n};\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/destroy.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/end-of-stream.js":
/*!****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/end-of-stream.js ***!
  \****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/end-of-stream with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\nvar ERR_STREAM_PREMATURE_CLOSE = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes.ERR_STREAM_PREMATURE_CLOSE);\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    callback.apply(this, args);\n  };\n}\n\nfunction noop() {}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction eos(stream, opts, callback) {\n  if (typeof opts === 'function') return eos(stream, null, opts);\n  if (!opts) opts = {};\n  callback = once(callback || noop);\n  var readable = opts.readable || opts.readable !== false && stream.readable;\n  var writable = opts.writable || opts.writable !== false && stream.writable;\n\n  var onlegacyfinish = function onlegacyfinish() {\n    if (!stream.writable) onfinish();\n  };\n\n  var writableEnded = stream._writableState && stream._writableState.finished;\n\n  var onfinish = function onfinish() {\n    writable = false;\n    writableEnded = true;\n    if (!readable) callback.call(stream);\n  };\n\n  var readableEnded = stream._readableState && stream._readableState.endEmitted;\n\n  var onend = function onend() {\n    readable = false;\n    readableEnded = true;\n    if (!writable) callback.call(stream);\n  };\n\n  var onerror = function onerror(err) {\n    callback.call(stream, err);\n  };\n\n  var onclose = function onclose() {\n    var err;\n\n    if (readable && !readableEnded) {\n      if (!stream._readableState || !stream._readableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n\n    if (writable && !writableEnded) {\n      if (!stream._writableState || !stream._writableState.ended) err = new ERR_STREAM_PREMATURE_CLOSE();\n      return callback.call(stream, err);\n    }\n  };\n\n  var onrequest = function onrequest() {\n    stream.req.on('finish', onfinish);\n  };\n\n  if (isRequest(stream)) {\n    stream.on('complete', onfinish);\n    stream.on('abort', onclose);\n    if (stream.req) onrequest();else stream.on('request', onrequest);\n  } else if (writable && !stream._writableState) {\n    // legacy streams\n    stream.on('end', onlegacyfinish);\n    stream.on('close', onlegacyfinish);\n  }\n\n  stream.on('end', onend);\n  stream.on('finish', onfinish);\n  if (opts.error !== false) stream.on('error', onerror);\n  stream.on('close', onclose);\n  return function () {\n    stream.removeListener('complete', onfinish);\n    stream.removeListener('abort', onclose);\n    stream.removeListener('request', onrequest);\n    if (stream.req) stream.req.removeListener('finish', onfinish);\n    stream.removeListener('end', onlegacyfinish);\n    stream.removeListener('close', onlegacyfinish);\n    stream.removeListener('finish', onfinish);\n    stream.removeListener('end', onend);\n    stream.removeListener('error', onerror);\n    stream.removeListener('close', onclose);\n  };\n}\n\nmodule.exports = eos;\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/end-of-stream.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/from-browser.js":
/*!***************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/from-browser.js ***!
  \***************************************************************************/
/***/ ((module) => {

eval("module.exports = function () {\n  throw new Error('Readable.from is not available in the browser')\n};\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/from-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/pipeline.js":
/*!***********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/pipeline.js ***!
  \***********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("// Ported from https://github.com/mafintosh/pump with\n// permission from the author, Mathias Buus (@mafintosh).\n\n\nvar eos;\n\nfunction once(callback) {\n  var called = false;\n  return function () {\n    if (called) return;\n    called = true;\n    callback.apply(void 0, arguments);\n  };\n}\n\nvar _require$codes = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes),\n    ERR_MISSING_ARGS = _require$codes.ERR_MISSING_ARGS,\n    ERR_STREAM_DESTROYED = _require$codes.ERR_STREAM_DESTROYED;\n\nfunction noop(err) {\n  // Rethrow the error if it exists to avoid swallowing it\n  if (err) throw err;\n}\n\nfunction isRequest(stream) {\n  return stream.setHeader && typeof stream.abort === 'function';\n}\n\nfunction destroyer(stream, reading, writing, callback) {\n  callback = once(callback);\n  var closed = false;\n  stream.on('close', function () {\n    closed = true;\n  });\n  if (eos === undefined) eos = __webpack_require__(/*! ./end-of-stream */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\n  eos(stream, {\n    readable: reading,\n    writable: writing\n  }, function (err) {\n    if (err) return callback(err);\n    closed = true;\n    callback();\n  });\n  var destroyed = false;\n  return function (err) {\n    if (closed) return;\n    if (destroyed) return;\n    destroyed = true; // request.destroy just do .end - .abort is what we want\n\n    if (isRequest(stream)) return stream.abort();\n    if (typeof stream.destroy === 'function') return stream.destroy();\n    callback(err || new ERR_STREAM_DESTROYED('pipe'));\n  };\n}\n\nfunction call(fn) {\n  fn();\n}\n\nfunction pipe(from, to) {\n  return from.pipe(to);\n}\n\nfunction popCallback(streams) {\n  if (!streams.length) return noop;\n  if (typeof streams[streams.length - 1] !== 'function') return noop;\n  return streams.pop();\n}\n\nfunction pipeline() {\n  for (var _len = arguments.length, streams = new Array(_len), _key = 0; _key < _len; _key++) {\n    streams[_key] = arguments[_key];\n  }\n\n  var callback = popCallback(streams);\n  if (Array.isArray(streams[0])) streams = streams[0];\n\n  if (streams.length < 2) {\n    throw new ERR_MISSING_ARGS('streams');\n  }\n\n  var error;\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1;\n    var writing = i > 0;\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err;\n      if (err) destroys.forEach(call);\n      if (reading) return;\n      destroys.forEach(call);\n      callback(error);\n    });\n  });\n  return streams.reduce(pipe);\n}\n\nmodule.exports = pipeline;\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/pipeline.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/state.js":
/*!********************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/state.js ***!
  \********************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

"use strict";
eval("\n\nvar ERR_INVALID_OPT_VALUE = (__webpack_require__(/*! ../../../errors */ \"./node_modules/readable-stream/errors-browser.js\").codes.ERR_INVALID_OPT_VALUE);\n\nfunction highWaterMarkFrom(options, isDuplex, duplexKey) {\n  return options.highWaterMark != null ? options.highWaterMark : isDuplex ? options[duplexKey] : null;\n}\n\nfunction getHighWaterMark(state, options, duplexKey, isDuplex) {\n  var hwm = highWaterMarkFrom(options, isDuplex, duplexKey);\n\n  if (hwm != null) {\n    if (!(isFinite(hwm) && Math.floor(hwm) === hwm) || hwm < 0) {\n      var name = isDuplex ? duplexKey : 'highWaterMark';\n      throw new ERR_INVALID_OPT_VALUE(name, hwm);\n    }\n\n    return Math.floor(hwm);\n  } // Default value\n\n\n  return state.objectMode ? 16 : 16 * 1024;\n}\n\nmodule.exports = {\n  getHighWaterMark: getHighWaterMark\n};\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/state.js?");

/***/ }),

/***/ "./node_modules/readable-stream/lib/internal/streams/stream-browser.js":
/*!*****************************************************************************!*\
  !*** ./node_modules/readable-stream/lib/internal/streams/stream-browser.js ***!
  \*****************************************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("module.exports = __webpack_require__(/*! events */ \"./node_modules/events/events.js\").EventEmitter;\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/lib/internal/streams/stream-browser.js?");

/***/ }),

/***/ "./node_modules/readable-stream/readable-browser.js":
/*!**********************************************************!*\
  !*** ./node_modules/readable-stream/readable-browser.js ***!
  \**********************************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("exports = module.exports = __webpack_require__(/*! ./lib/_stream_readable.js */ \"./node_modules/readable-stream/lib/_stream_readable.js\");\nexports.Stream = exports;\nexports.Readable = exports;\nexports.Writable = __webpack_require__(/*! ./lib/_stream_writable.js */ \"./node_modules/readable-stream/lib/_stream_writable.js\");\nexports.Duplex = __webpack_require__(/*! ./lib/_stream_duplex.js */ \"./node_modules/readable-stream/lib/_stream_duplex.js\");\nexports.Transform = __webpack_require__(/*! ./lib/_stream_transform.js */ \"./node_modules/readable-stream/lib/_stream_transform.js\");\nexports.PassThrough = __webpack_require__(/*! ./lib/_stream_passthrough.js */ \"./node_modules/readable-stream/lib/_stream_passthrough.js\");\nexports.finished = __webpack_require__(/*! ./lib/internal/streams/end-of-stream.js */ \"./node_modules/readable-stream/lib/internal/streams/end-of-stream.js\");\nexports.pipeline = __webpack_require__(/*! ./lib/internal/streams/pipeline.js */ \"./node_modules/readable-stream/lib/internal/streams/pipeline.js\");\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-stream/readable-browser.js?");

/***/ }),

/***/ "./node_modules/readable-web-to-node-stream/lib/index.js":
/*!***************************************************************!*\
  !*** ./node_modules/readable-web-to-node-stream/lib/index.js ***!
  \***************************************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

"use strict";
eval("\nObject.defineProperty(exports, \"__esModule\", ({ value: true }));\nexports.ReadableWebToNodeStream = void 0;\nconst readable_stream_1 = __webpack_require__(/*! readable-stream */ \"./node_modules/readable-stream/readable-browser.js\");\n/**\n * Converts a Web-API stream into Node stream.Readable class\n * Node stream readable: https://nodejs.org/api/stream.html#stream_readable_streams\n * Web API readable-stream: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream\n * Node readable stream: https://nodejs.org/api/stream.html#stream_readable_streams\n */\nclass ReadableWebToNodeStream extends readable_stream_1.Readable {\n    /**\n     *\n     * @param stream ReadableStream: https://developer.mozilla.org/en-US/docs/Web/API/ReadableStream\n     */\n    constructor(stream) {\n        super();\n        this.bytesRead = 0;\n        this.released = false;\n        this.reader = stream.getReader();\n    }\n    /**\n     * Implementation of readable._read(size).\n     * When readable._read() is called, if data is available from the resource,\n     * the implementation should begin pushing that data into the read queue\n     * https://nodejs.org/api/stream.html#stream_readable_read_size_1\n     */\n    async _read() {\n        // Should start pushing data into the queue\n        // Read data from the underlying Web-API-readable-stream\n        if (this.released) {\n            this.push(null); // Signal EOF\n            return;\n        }\n        this.pendingRead = this.reader.read();\n        const data = await this.pendingRead;\n        // clear the promise before pushing pushing new data to the queue and allow sequential calls to _read()\n        delete this.pendingRead;\n        if (data.done || this.released) {\n            this.push(null); // Signal EOF\n        }\n        else {\n            this.bytesRead += data.value.length;\n            this.push(data.value); // Push new data to the queue\n        }\n    }\n    /**\n     * If there is no unresolved read call to Web-API ReadableStream immediately returns;\n     * otherwise will wait until the read is resolved.\n     */\n    async waitForReadToComplete() {\n        if (this.pendingRead) {\n            await this.pendingRead;\n        }\n    }\n    /**\n     * Close wrapper\n     */\n    async close() {\n        await this.syncAndRelease();\n    }\n    async syncAndRelease() {\n        this.released = true;\n        await this.waitForReadToComplete();\n        await this.reader.releaseLock();\n    }\n}\nexports.ReadableWebToNodeStream = ReadableWebToNodeStream;\n//# sourceMappingURL=index.js.map\n\n//# sourceURL=webpack://discord-bot/./node_modules/readable-web-to-node-stream/lib/index.js?");

/***/ }),

/***/ "./node_modules/util-deprecate/browser.js":
/*!************************************************!*\
  !*** ./node_modules/util-deprecate/browser.js ***!
  \************************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("\n/**\n * Module exports.\n */\n\nmodule.exports = deprecate;\n\n/**\n * Mark that a method should not be used.\n * Returns a modified function which warns once by default.\n *\n * If `localStorage.noDeprecation = true` is set, then it is a no-op.\n *\n * If `localStorage.throwDeprecation = true` is set, then deprecated functions\n * will throw an Error when invoked.\n *\n * If `localStorage.traceDeprecation = true` is set, then deprecated functions\n * will invoke `console.trace()` instead of `console.error()`.\n *\n * @param {Function} fn - the function to deprecate\n * @param {String} msg - the string to print to the console when `fn` is invoked\n * @returns {Function} a new \"deprecated\" version of `fn`\n * @api public\n */\n\nfunction deprecate (fn, msg) {\n  if (config('noDeprecation')) {\n    return fn;\n  }\n\n  var warned = false;\n  function deprecated() {\n    if (!warned) {\n      if (config('throwDeprecation')) {\n        throw new Error(msg);\n      } else if (config('traceDeprecation')) {\n        console.trace(msg);\n      } else {\n        console.warn(msg);\n      }\n      warned = true;\n    }\n    return fn.apply(this, arguments);\n  }\n\n  return deprecated;\n}\n\n/**\n * Checks `localStorage` for boolean values for the given `name`.\n *\n * @param {String} name\n * @returns {Boolean}\n * @api private\n */\n\nfunction config (name) {\n  // accessing global.localStorage can trigger a DOMException in sandboxed iframes\n  try {\n    if (!__webpack_require__.g.localStorage) return false;\n  } catch (_) {\n    return false;\n  }\n  var val = __webpack_require__.g.localStorage[name];\n  if (null == val) return false;\n  return String(val).toLowerCase() === 'true';\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/util-deprecate/browser.js?");

/***/ }),

/***/ "./node_modules/file-type/browser.js":
/*!*******************************************!*\
  !*** ./node_modules/file-type/browser.js ***!
  \*******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"fileTypeFromBlob\": () => (/* binding */ fileTypeFromBlob),\n/* harmony export */   \"fileTypeFromBuffer\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_2__.fileTypeFromBuffer),\n/* harmony export */   \"fileTypeFromStream\": () => (/* binding */ fileTypeFromStream),\n/* harmony export */   \"fileTypeFromTokenizer\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_2__.fileTypeFromTokenizer),\n/* harmony export */   \"fileTypeStream\": () => (/* reexport safe */ _core_js__WEBPACK_IMPORTED_MODULE_2__.fileTypeStream)\n/* harmony export */ });\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n/* harmony import */ var readable_web_to_node_stream__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! readable-web-to-node-stream */ \"./node_modules/readable-web-to-node-stream/lib/index.js\");\n/* harmony import */ var _core_js__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! ./core.js */ \"./node_modules/file-type/core.js\");\n\n\n\n\n/**\nConvert Blobs to ArrayBuffer.\n\n@param {Blob} blob - Web API Blob.\n@returns {Promise<ArrayBuffer>}\n*/\nfunction blobToArrayBuffer(blob) {\n\tif (blob.arrayBuffer) {\n\t\treturn blob.arrayBuffer();\n\t}\n\n\t// TODO: Remove when stop supporting older environments\n\treturn new Promise((resolve, reject) => {\n\t\tconst fileReader = new FileReader();\n\t\tfileReader.addEventListener('loadend', event => {\n\t\t\tresolve(event.target.result);\n\t\t});\n\n\t\tfileReader.addEventListener('error', event => {\n\t\t\treject(new Error(event.message));\n\t\t});\n\n\t\tfileReader.addEventListener('abort', event => {\n\t\t\treject(new Error(event.type));\n\t\t});\n\n\t\tfileReader.readAsArrayBuffer(blob);\n\t});\n}\n\nasync function fileTypeFromStream(stream) {\n\tconst readableWebToNodeStream = new readable_web_to_node_stream__WEBPACK_IMPORTED_MODULE_1__.ReadableWebToNodeStream(stream);\n\tconst fileType = await (0,_core_js__WEBPACK_IMPORTED_MODULE_2__.fileTypeFromStream)(readableWebToNodeStream);\n\tawait readableWebToNodeStream.close();\n\treturn fileType;\n}\n\nasync function fileTypeFromBlob(blob) {\n\tconst buffer = await blobToArrayBuffer(blob);\n\treturn (0,_core_js__WEBPACK_IMPORTED_MODULE_2__.fileTypeFromBuffer)(node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.from(buffer));\n}\n\n\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/file-type/browser.js?");

/***/ }),

/***/ "./node_modules/file-type/core.js":
/*!****************************************!*\
  !*** ./node_modules/file-type/core.js ***!
  \****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"fileTypeFromBuffer\": () => (/* binding */ fileTypeFromBuffer),\n/* harmony export */   \"fileTypeFromStream\": () => (/* binding */ fileTypeFromStream),\n/* harmony export */   \"fileTypeFromTokenizer\": () => (/* binding */ fileTypeFromTokenizer),\n/* harmony export */   \"fileTypeStream\": () => (/* binding */ fileTypeStream),\n/* harmony export */   \"supportedExtensions\": () => (/* binding */ supportedExtensions),\n/* harmony export */   \"supportedMimeTypes\": () => (/* binding */ supportedMimeTypes)\n/* harmony export */ });\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n/* harmony import */ var token_types__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! token-types */ \"./node_modules/token-types/lib/index.js\");\n/* harmony import */ var strtok3_core__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! strtok3/core */ \"./node_modules/strtok3/lib/core.js\");\n/* harmony import */ var _util_js__WEBPACK_IMPORTED_MODULE_3__ = __webpack_require__(/*! ./util.js */ \"./node_modules/file-type/util.js\");\n/* harmony import */ var _supported_js__WEBPACK_IMPORTED_MODULE_4__ = __webpack_require__(/*! ./supported.js */ \"./node_modules/file-type/supported.js\");\n\n\n // eslint-disable-line n/file-extension-in-import\n\n\n\nconst minimumBytes = 4100; // A fair amount of file-types are detectable within this range.\n\nasync function fileTypeFromStream(stream) {\n\tconst tokenizer = await strtok3_core__WEBPACK_IMPORTED_MODULE_2__.fromStream(stream);\n\ttry {\n\t\treturn await fileTypeFromTokenizer(tokenizer);\n\t} finally {\n\t\tawait tokenizer.close();\n\t}\n}\n\nasync function fileTypeFromBuffer(input) {\n\tif (!(input instanceof Uint8Array || input instanceof ArrayBuffer)) {\n\t\tthrow new TypeError(`Expected the \\`input\\` argument to be of type \\`Uint8Array\\` or \\`Buffer\\` or \\`ArrayBuffer\\`, got \\`${typeof input}\\``);\n\t}\n\n\tconst buffer = input instanceof Uint8Array ? input : new Uint8Array(input);\n\n\tif (!(buffer?.length > 1)) {\n\t\treturn;\n\t}\n\n\treturn fileTypeFromTokenizer(strtok3_core__WEBPACK_IMPORTED_MODULE_2__.fromBuffer(buffer));\n}\n\nfunction _check(buffer, headers, options) {\n\toptions = {\n\t\toffset: 0,\n\t\t...options,\n\t};\n\n\tfor (const [index, header] of headers.entries()) {\n\t\t// If a bitmask is set\n\t\tif (options.mask) {\n\t\t\t// If header doesn't equal `buf` with bits masked off\n\t\t\tif (header !== (options.mask[index] & buffer[index + options.offset])) {\n\t\t\t\treturn false;\n\t\t\t}\n\t\t} else if (header !== buffer[index + options.offset]) {\n\t\t\treturn false;\n\t\t}\n\t}\n\n\treturn true;\n}\n\nasync function fileTypeFromTokenizer(tokenizer) {\n\ttry {\n\t\treturn new FileTypeParser().parse(tokenizer);\n\t} catch (error) {\n\t\tif (!(error instanceof strtok3_core__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError)) {\n\t\t\tthrow error;\n\t\t}\n\t}\n}\n\nclass FileTypeParser {\n\tcheck(header, options) {\n\t\treturn _check(this.buffer, header, options);\n\t}\n\n\tcheckString(header, options) {\n\t\treturn this.check((0,_util_js__WEBPACK_IMPORTED_MODULE_3__.stringToBytes)(header), options);\n\t}\n\n\tasync parse(tokenizer) {\n\t\tthis.buffer = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(minimumBytes);\n\n\t\t// Keep reading until EOF if the file size is unknown.\n\t\tif (tokenizer.fileInfo.size === undefined) {\n\t\t\ttokenizer.fileInfo.size = Number.MAX_SAFE_INTEGER;\n\t\t}\n\n\t\tthis.tokenizer = tokenizer;\n\n\t\tawait tokenizer.peekBuffer(this.buffer, {length: 12, mayBeLess: true});\n\n\t\t// -- 2-byte signatures --\n\n\t\tif (this.check([0x42, 0x4D])) {\n\t\t\treturn {\n\t\t\t\text: 'bmp',\n\t\t\t\tmime: 'image/bmp',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x0B, 0x77])) {\n\t\t\treturn {\n\t\t\t\text: 'ac3',\n\t\t\t\tmime: 'audio/vnd.dolby.dd-raw',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x78, 0x01])) {\n\t\t\treturn {\n\t\t\t\text: 'dmg',\n\t\t\t\tmime: 'application/x-apple-diskimage',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x4D, 0x5A])) {\n\t\t\treturn {\n\t\t\t\text: 'exe',\n\t\t\t\tmime: 'application/x-msdownload',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x25, 0x21])) {\n\t\t\tawait tokenizer.peekBuffer(this.buffer, {length: 24, mayBeLess: true});\n\n\t\t\tif (\n\t\t\t\tthis.checkString('PS-Adobe-', {offset: 2})\n\t\t\t\t&& this.checkString(' EPSF-', {offset: 14})\n\t\t\t) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'eps',\n\t\t\t\t\tmime: 'application/eps',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'ps',\n\t\t\t\tmime: 'application/postscript',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x1F, 0xA0])\n\t\t\t|| this.check([0x1F, 0x9D])\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'Z',\n\t\t\t\tmime: 'application/x-compress',\n\t\t\t};\n\t\t}\n\n\t\t// -- 3-byte signatures --\n\n\t\tif (this.check([0xEF, 0xBB, 0xBF])) { // UTF-8-BOM\n\t\t\t// Strip off UTF-8-BOM\n\t\t\tthis.tokenizer.ignore(3);\n\t\t\treturn this.parse(tokenizer);\n\t\t}\n\n\t\tif (this.check([0x47, 0x49, 0x46])) {\n\t\t\treturn {\n\t\t\t\text: 'gif',\n\t\t\t\tmime: 'image/gif',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x49, 0x49, 0xBC])) {\n\t\t\treturn {\n\t\t\t\text: 'jxr',\n\t\t\t\tmime: 'image/vnd.ms-photo',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x1F, 0x8B, 0x8])) {\n\t\t\treturn {\n\t\t\t\text: 'gz',\n\t\t\t\tmime: 'application/gzip',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x42, 0x5A, 0x68])) {\n\t\t\treturn {\n\t\t\t\text: 'bz2',\n\t\t\t\tmime: 'application/x-bzip2',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('ID3')) {\n\t\t\tawait tokenizer.ignore(6); // Skip ID3 header until the header size\n\t\t\tconst id3HeaderLength = await tokenizer.readToken(_util_js__WEBPACK_IMPORTED_MODULE_3__.uint32SyncSafeToken);\n\t\t\tif (tokenizer.position + id3HeaderLength > tokenizer.fileInfo.size) {\n\t\t\t\t// Guess file type based on ID3 header for backward compatibility\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp3',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tawait tokenizer.ignore(id3HeaderLength);\n\t\t\treturn fileTypeFromTokenizer(tokenizer); // Skip ID3 header, recursion\n\t\t}\n\n\t\t// Musepack, SV7\n\t\tif (this.checkString('MP+')) {\n\t\t\treturn {\n\t\t\t\text: 'mpc',\n\t\t\t\tmime: 'audio/x-musepack',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\t(this.buffer[0] === 0x43 || this.buffer[0] === 0x46)\n\t\t\t&& this.check([0x57, 0x53], {offset: 1})\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'swf',\n\t\t\t\tmime: 'application/x-shockwave-flash',\n\t\t\t};\n\t\t}\n\n\t\t// -- 4-byte signatures --\n\n\t\t// Requires a sample size of 4 bytes\n\t\tif (this.check([0xFF, 0xD8, 0xFF])) {\n\t\t\tif (this.check([0xF7], {offset: 3})) { // JPG7/SOF55, indicating a ISO/IEC 14495 / JPEG-LS file\n\t\t\t\treturn {\n\t\t\t\t\text: 'jls',\n\t\t\t\t\tmime: 'image/jls',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'jpg',\n\t\t\t\tmime: 'image/jpeg',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('FLIF')) {\n\t\t\treturn {\n\t\t\t\text: 'flif',\n\t\t\t\tmime: 'image/flif',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('8BPS')) {\n\t\t\treturn {\n\t\t\t\text: 'psd',\n\t\t\t\tmime: 'image/vnd.adobe.photoshop',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('WEBP', {offset: 8})) {\n\t\t\treturn {\n\t\t\t\text: 'webp',\n\t\t\t\tmime: 'image/webp',\n\t\t\t};\n\t\t}\n\n\t\t// Musepack, SV8\n\t\tif (this.checkString('MPCK')) {\n\t\t\treturn {\n\t\t\t\text: 'mpc',\n\t\t\t\tmime: 'audio/x-musepack',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('FORM')) {\n\t\t\treturn {\n\t\t\t\text: 'aif',\n\t\t\t\tmime: 'audio/aiff',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('icns', {offset: 0})) {\n\t\t\treturn {\n\t\t\t\text: 'icns',\n\t\t\t\tmime: 'image/icns',\n\t\t\t};\n\t\t}\n\n\t\t// Zip-based file formats\n\t\t// Need to be before the `zip` check\n\t\tif (this.check([0x50, 0x4B, 0x3, 0x4])) { // Local file header signature\n\t\t\ttry {\n\t\t\t\twhile (tokenizer.position + 30 < tokenizer.fileInfo.size) {\n\t\t\t\t\tawait tokenizer.readBuffer(this.buffer, {length: 30});\n\n\t\t\t\t\t// https://en.wikipedia.org/wiki/Zip_(file_format)#File_headers\n\t\t\t\t\tconst zipHeader = {\n\t\t\t\t\t\tcompressedSize: this.buffer.readUInt32LE(18),\n\t\t\t\t\t\tuncompressedSize: this.buffer.readUInt32LE(22),\n\t\t\t\t\t\tfilenameLength: this.buffer.readUInt16LE(26),\n\t\t\t\t\t\textraFieldLength: this.buffer.readUInt16LE(28),\n\t\t\t\t\t};\n\n\t\t\t\t\tzipHeader.filename = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(zipHeader.filenameLength, 'utf-8'));\n\t\t\t\t\tawait tokenizer.ignore(zipHeader.extraFieldLength);\n\n\t\t\t\t\t// Assumes signed `.xpi` from addons.mozilla.org\n\t\t\t\t\tif (zipHeader.filename === 'META-INF/mozilla.rsa') {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'xpi',\n\t\t\t\t\t\t\tmime: 'application/x-xpinstall',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (zipHeader.filename.endsWith('.rels') || zipHeader.filename.endsWith('.xml')) {\n\t\t\t\t\t\tconst type = zipHeader.filename.split('/')[0];\n\t\t\t\t\t\tswitch (type) {\n\t\t\t\t\t\t\tcase '_rels':\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t\tcase 'word':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'docx',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'ppt':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'pptx',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'xl':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t\t\tbreak;\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tif (zipHeader.filename.startsWith('xl/')) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'xlsx',\n\t\t\t\t\t\t\tmime: 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (zipHeader.filename.startsWith('3D/') && zipHeader.filename.endsWith('.model')) {\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: '3mf',\n\t\t\t\t\t\t\tmime: 'model/3mf',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\t// The docx, xlsx and pptx file types extend the Office Open XML file format:\n\t\t\t\t\t// https://en.wikipedia.org/wiki/Office_Open_XML_file_formats\n\t\t\t\t\t// We look for:\n\t\t\t\t\t// - one entry named '[Content_Types].xml' or '_rels/.rels',\n\t\t\t\t\t// - one entry indicating specific type of file.\n\t\t\t\t\t// MS Office, OpenOffice and LibreOffice may put the parts in different order, so the check should not rely on it.\n\t\t\t\t\tif (zipHeader.filename === 'mimetype' && zipHeader.compressedSize === zipHeader.uncompressedSize) {\n\t\t\t\t\t\tlet mimeType = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(zipHeader.compressedSize, 'utf-8'));\n\t\t\t\t\t\tmimeType = mimeType.trim();\n\n\t\t\t\t\t\tswitch (mimeType) {\n\t\t\t\t\t\t\tcase 'application/epub+zip':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'epub',\n\t\t\t\t\t\t\t\t\tmime: 'application/epub+zip',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.text':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'odt',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.text',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.spreadsheet':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'ods',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.spreadsheet',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tcase 'application/vnd.oasis.opendocument.presentation':\n\t\t\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\t\t\text: 'odp',\n\t\t\t\t\t\t\t\t\tmime: 'application/vnd.oasis.opendocument.presentation',\n\t\t\t\t\t\t\t\t};\n\t\t\t\t\t\t\tdefault:\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\t// Try to find next header manually when current one is corrupted\n\t\t\t\t\tif (zipHeader.compressedSize === 0) {\n\t\t\t\t\t\tlet nextHeaderIndex = -1;\n\n\t\t\t\t\t\twhile (nextHeaderIndex < 0 && (tokenizer.position < tokenizer.fileInfo.size)) {\n\t\t\t\t\t\t\tawait tokenizer.peekBuffer(this.buffer, {mayBeLess: true});\n\n\t\t\t\t\t\t\tnextHeaderIndex = this.buffer.indexOf('504B0304', 0, 'hex');\n\t\t\t\t\t\t\t// Move position to the next header if found, skip the whole buffer otherwise\n\t\t\t\t\t\t\tawait tokenizer.ignore(nextHeaderIndex >= 0 ? nextHeaderIndex : this.buffer.length);\n\t\t\t\t\t\t}\n\t\t\t\t\t} else {\n\t\t\t\t\t\tawait tokenizer.ignore(zipHeader.compressedSize);\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t} catch (error) {\n\t\t\t\tif (!(error instanceof strtok3_core__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError)) {\n\t\t\t\t\tthrow error;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'zip',\n\t\t\t\tmime: 'application/zip',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('OggS')) {\n\t\t\t// This is an OGG container\n\t\t\tawait tokenizer.ignore(28);\n\t\t\tconst type = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(8);\n\t\t\tawait tokenizer.readBuffer(type);\n\n\t\t\t// Needs to be before `ogg` check\n\t\t\tif (_check(type, [0x4F, 0x70, 0x75, 0x73, 0x48, 0x65, 0x61, 0x64])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'opus',\n\t\t\t\t\tmime: 'audio/opus',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If ' theora' in header.\n\t\t\tif (_check(type, [0x80, 0x74, 0x68, 0x65, 0x6F, 0x72, 0x61])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ogv',\n\t\t\t\t\tmime: 'video/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If '\\x01video' in header.\n\t\t\tif (_check(type, [0x01, 0x76, 0x69, 0x64, 0x65, 0x6F, 0x00])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ogm',\n\t\t\t\t\tmime: 'video/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If ' FLAC' in header  https://xiph.org/flac/faq.html\n\t\t\tif (_check(type, [0x7F, 0x46, 0x4C, 0x41, 0x43])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'oga',\n\t\t\t\t\tmime: 'audio/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// 'Speex  ' in header https://en.wikipedia.org/wiki/Speex\n\t\t\tif (_check(type, [0x53, 0x70, 0x65, 0x65, 0x78, 0x20, 0x20])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'spx',\n\t\t\t\t\tmime: 'audio/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// If '\\x01vorbis' in header\n\t\t\tif (_check(type, [0x01, 0x76, 0x6F, 0x72, 0x62, 0x69, 0x73])) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ogg',\n\t\t\t\t\tmime: 'audio/ogg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Default OGG container https://www.iana.org/assignments/media-types/application/ogg\n\t\t\treturn {\n\t\t\t\text: 'ogx',\n\t\t\t\tmime: 'application/ogg',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x50, 0x4B])\n\t\t\t&& (this.buffer[2] === 0x3 || this.buffer[2] === 0x5 || this.buffer[2] === 0x7)\n\t\t\t&& (this.buffer[3] === 0x4 || this.buffer[3] === 0x6 || this.buffer[3] === 0x8)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'zip',\n\t\t\t\tmime: 'application/zip',\n\t\t\t};\n\t\t}\n\n\t\t//\n\n\t\t// File Type Box (https://en.wikipedia.org/wiki/ISO_base_media_file_format)\n\t\t// It's not required to be first, but it's recommended to be. Almost all ISO base media files start with `ftyp` box.\n\t\t// `ftyp` box must contain a brand major identifier, which must consist of ISO 8859-1 printable characters.\n\t\t// Here we check for 8859-1 printable characters (for simplicity, it's a mask which also catches one non-printable character).\n\t\tif (\n\t\t\tthis.checkString('ftyp', {offset: 4})\n\t\t\t&& (this.buffer[8] & 0x60) !== 0x00 // Brand major, first character ASCII?\n\t\t) {\n\t\t\t// They all can have MIME `video/mp4` except `application/mp4` special-case which is hard to detect.\n\t\t\t// For some cases, we're specific, everything else falls to `video/mp4` with `mp4` extension.\n\t\t\tconst brandMajor = this.buffer.toString('binary', 8, 12).replace('\\0', ' ').trim();\n\t\t\tswitch (brandMajor) {\n\t\t\t\tcase 'avif':\n\t\t\t\tcase 'avis':\n\t\t\t\t\treturn {ext: 'avif', mime: 'image/avif'};\n\t\t\t\tcase 'mif1':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heif'};\n\t\t\t\tcase 'msf1':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heif-sequence'};\n\t\t\t\tcase 'heic':\n\t\t\t\tcase 'heix':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heic'};\n\t\t\t\tcase 'hevc':\n\t\t\t\tcase 'hevx':\n\t\t\t\t\treturn {ext: 'heic', mime: 'image/heic-sequence'};\n\t\t\t\tcase 'qt':\n\t\t\t\t\treturn {ext: 'mov', mime: 'video/quicktime'};\n\t\t\t\tcase 'M4V':\n\t\t\t\tcase 'M4VH':\n\t\t\t\tcase 'M4VP':\n\t\t\t\t\treturn {ext: 'm4v', mime: 'video/x-m4v'};\n\t\t\t\tcase 'M4P':\n\t\t\t\t\treturn {ext: 'm4p', mime: 'video/mp4'};\n\t\t\t\tcase 'M4B':\n\t\t\t\t\treturn {ext: 'm4b', mime: 'audio/mp4'};\n\t\t\t\tcase 'M4A':\n\t\t\t\t\treturn {ext: 'm4a', mime: 'audio/x-m4a'};\n\t\t\t\tcase 'F4V':\n\t\t\t\t\treturn {ext: 'f4v', mime: 'video/mp4'};\n\t\t\t\tcase 'F4P':\n\t\t\t\t\treturn {ext: 'f4p', mime: 'video/mp4'};\n\t\t\t\tcase 'F4A':\n\t\t\t\t\treturn {ext: 'f4a', mime: 'audio/mp4'};\n\t\t\t\tcase 'F4B':\n\t\t\t\t\treturn {ext: 'f4b', mime: 'audio/mp4'};\n\t\t\t\tcase 'crx':\n\t\t\t\t\treturn {ext: 'cr3', mime: 'image/x-canon-cr3'};\n\t\t\t\tdefault:\n\t\t\t\t\tif (brandMajor.startsWith('3g')) {\n\t\t\t\t\t\tif (brandMajor.startsWith('3g2')) {\n\t\t\t\t\t\t\treturn {ext: '3g2', mime: 'video/3gpp2'};\n\t\t\t\t\t\t}\n\n\t\t\t\t\t\treturn {ext: '3gp', mime: 'video/3gpp'};\n\t\t\t\t\t}\n\n\t\t\t\t\treturn {ext: 'mp4', mime: 'video/mp4'};\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('MThd')) {\n\t\t\treturn {\n\t\t\t\text: 'mid',\n\t\t\t\tmime: 'audio/midi',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('wOFF')\n\t\t\t&& (\n\t\t\t\tthis.check([0x00, 0x01, 0x00, 0x00], {offset: 4})\n\t\t\t\t|| this.checkString('OTTO', {offset: 4})\n\t\t\t)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'woff',\n\t\t\t\tmime: 'font/woff',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('wOF2')\n\t\t\t&& (\n\t\t\t\tthis.check([0x00, 0x01, 0x00, 0x00], {offset: 4})\n\t\t\t\t|| this.checkString('OTTO', {offset: 4})\n\t\t\t)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'woff2',\n\t\t\t\tmime: 'font/woff2',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xD4, 0xC3, 0xB2, 0xA1]) || this.check([0xA1, 0xB2, 0xC3, 0xD4])) {\n\t\t\treturn {\n\t\t\t\text: 'pcap',\n\t\t\t\tmime: 'application/vnd.tcpdump.pcap',\n\t\t\t};\n\t\t}\n\n\t\t// Sony DSD Stream File (DSF)\n\t\tif (this.checkString('DSD ')) {\n\t\t\treturn {\n\t\t\t\text: 'dsf',\n\t\t\t\tmime: 'audio/x-dsf', // Non-standard\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('LZIP')) {\n\t\t\treturn {\n\t\t\t\text: 'lz',\n\t\t\t\tmime: 'application/x-lzip',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('fLaC')) {\n\t\t\treturn {\n\t\t\t\text: 'flac',\n\t\t\t\tmime: 'audio/x-flac',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x42, 0x50, 0x47, 0xFB])) {\n\t\t\treturn {\n\t\t\t\text: 'bpg',\n\t\t\t\tmime: 'image/bpg',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('wvpk')) {\n\t\t\treturn {\n\t\t\t\text: 'wv',\n\t\t\t\tmime: 'audio/wavpack',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('%PDF')) {\n\t\t\tawait tokenizer.ignore(1350);\n\t\t\tconst maxBufferSize = 10 * 1024 * 1024;\n\t\t\tconst buffer = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(Math.min(maxBufferSize, tokenizer.fileInfo.size));\n\t\t\tawait tokenizer.readBuffer(buffer, {mayBeLess: true});\n\n\t\t\t// Check if this is an Adobe Illustrator file\n\t\t\tif (buffer.includes(node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.from('AIPrivateData'))) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ai',\n\t\t\t\t\tmime: 'application/postscript',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Assume this is just a normal PDF\n\t\t\treturn {\n\t\t\t\text: 'pdf',\n\t\t\t\tmime: 'application/pdf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x61, 0x73, 0x6D])) {\n\t\t\treturn {\n\t\t\t\text: 'wasm',\n\t\t\t\tmime: 'application/wasm',\n\t\t\t};\n\t\t}\n\n\t\t// TIFF, little-endian type\n\t\tif (this.check([0x49, 0x49])) {\n\t\t\tconst fileType = await this.readTiffHeader(false);\n\t\t\tif (fileType) {\n\t\t\t\treturn fileType;\n\t\t\t}\n\t\t}\n\n\t\t// TIFF, big-endian type\n\t\tif (this.check([0x4D, 0x4D])) {\n\t\t\tconst fileType = await this.readTiffHeader(true);\n\t\t\tif (fileType) {\n\t\t\t\treturn fileType;\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('MAC ')) {\n\t\t\treturn {\n\t\t\t\text: 'ape',\n\t\t\t\tmime: 'audio/ape',\n\t\t\t};\n\t\t}\n\n\t\t// https://github.com/threatstack/libmagic/blob/master/magic/Magdir/matroska\n\t\tif (this.check([0x1A, 0x45, 0xDF, 0xA3])) { // Root element: EBML\n\t\t\tasync function readField() {\n\t\t\t\tconst msb = await tokenizer.peekNumber(token_types__WEBPACK_IMPORTED_MODULE_1__.UINT8);\n\t\t\t\tlet mask = 0x80;\n\t\t\t\tlet ic = 0; // 0 = A, 1 = B, 2 = C, 3\n\t\t\t\t// = D\n\n\t\t\t\twhile ((msb & mask) === 0 && mask !== 0) {\n\t\t\t\t\t++ic;\n\t\t\t\t\tmask >>= 1;\n\t\t\t\t}\n\n\t\t\t\tconst id = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(ic + 1);\n\t\t\t\tawait tokenizer.readBuffer(id);\n\t\t\t\treturn id;\n\t\t\t}\n\n\t\t\tasync function readElement() {\n\t\t\t\tconst id = await readField();\n\t\t\t\tconst lengthField = await readField();\n\t\t\t\tlengthField[0] ^= 0x80 >> (lengthField.length - 1);\n\t\t\t\tconst nrLength = Math.min(6, lengthField.length); // JavaScript can max read 6 bytes integer\n\t\t\t\treturn {\n\t\t\t\t\tid: id.readUIntBE(0, id.length),\n\t\t\t\t\tlen: lengthField.readUIntBE(lengthField.length - nrLength, nrLength),\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tasync function readChildren(children) {\n\t\t\t\twhile (children > 0) {\n\t\t\t\t\tconst element = await readElement();\n\t\t\t\t\tif (element.id === 0x42_82) {\n\t\t\t\t\t\tconst rawValue = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(element.len, 'utf-8'));\n\t\t\t\t\t\treturn rawValue.replace(/\\00.*$/g, ''); // Return DocType\n\t\t\t\t\t}\n\n\t\t\t\t\tawait tokenizer.ignore(element.len); // ignore payload\n\t\t\t\t\t--children;\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tconst re = await readElement();\n\t\t\tconst docType = await readChildren(re.len);\n\n\t\t\tswitch (docType) {\n\t\t\t\tcase 'webm':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'webm',\n\t\t\t\t\t\tmime: 'video/webm',\n\t\t\t\t\t};\n\n\t\t\t\tcase 'matroska':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'mkv',\n\t\t\t\t\t\tmime: 'video/x-matroska',\n\t\t\t\t\t};\n\n\t\t\t\tdefault:\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\t// RIFF file format which might be AVI, WAV, QCP, etc\n\t\tif (this.check([0x52, 0x49, 0x46, 0x46])) {\n\t\t\tif (this.check([0x41, 0x56, 0x49], {offset: 8})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'avi',\n\t\t\t\t\tmime: 'video/vnd.avi',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (this.check([0x57, 0x41, 0x56, 0x45], {offset: 8})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'wav',\n\t\t\t\t\tmime: 'audio/vnd.wave',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// QLCM, QCP file\n\t\t\tif (this.check([0x51, 0x4C, 0x43, 0x4D], {offset: 8})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'qcp',\n\t\t\t\t\tmime: 'audio/qcelp',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('SQLi')) {\n\t\t\treturn {\n\t\t\t\text: 'sqlite',\n\t\t\t\tmime: 'application/x-sqlite3',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x4E, 0x45, 0x53, 0x1A])) {\n\t\t\treturn {\n\t\t\t\text: 'nes',\n\t\t\t\tmime: 'application/x-nintendo-nes-rom',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('Cr24')) {\n\t\t\treturn {\n\t\t\t\text: 'crx',\n\t\t\t\tmime: 'application/x-google-chrome-extension',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('MSCF')\n\t\t\t|| this.checkString('ISc(')\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'cab',\n\t\t\t\tmime: 'application/vnd.ms-cab-compressed',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xED, 0xAB, 0xEE, 0xDB])) {\n\t\t\treturn {\n\t\t\t\text: 'rpm',\n\t\t\t\tmime: 'application/x-rpm',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xC5, 0xD0, 0xD3, 0xC6])) {\n\t\t\treturn {\n\t\t\t\text: 'eps',\n\t\t\t\tmime: 'application/eps',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x28, 0xB5, 0x2F, 0xFD])) {\n\t\t\treturn {\n\t\t\t\text: 'zst',\n\t\t\t\tmime: 'application/zstd',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x7F, 0x45, 0x4C, 0x46])) {\n\t\t\treturn {\n\t\t\t\text: 'elf',\n\t\t\t\tmime: 'application/x-elf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x21, 0x42, 0x44, 0x4E])) {\n\t\t\treturn {\n\t\t\t\text: 'pst',\n\t\t\t\tmime: 'application/vnd.ms-outlook',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('PAR1')) {\n\t\t\treturn {\n\t\t\t\text: 'parquet',\n\t\t\t\tmime: 'application/x-parquet',\n\t\t\t};\n\t\t}\n\n\t\t// -- 5-byte signatures --\n\n\t\tif (this.check([0x4F, 0x54, 0x54, 0x4F, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'otf',\n\t\t\t\tmime: 'font/otf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('#!AMR')) {\n\t\t\treturn {\n\t\t\t\text: 'amr',\n\t\t\t\tmime: 'audio/amr',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('{\\\\rtf')) {\n\t\t\treturn {\n\t\t\t\text: 'rtf',\n\t\t\t\tmime: 'application/rtf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x46, 0x4C, 0x56, 0x01])) {\n\t\t\treturn {\n\t\t\t\text: 'flv',\n\t\t\t\tmime: 'video/x-flv',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('IMPM')) {\n\t\t\treturn {\n\t\t\t\text: 'it',\n\t\t\t\tmime: 'audio/x-it',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.checkString('-lh0-', {offset: 2})\n\t\t\t|| this.checkString('-lh1-', {offset: 2})\n\t\t\t|| this.checkString('-lh2-', {offset: 2})\n\t\t\t|| this.checkString('-lh3-', {offset: 2})\n\t\t\t|| this.checkString('-lh4-', {offset: 2})\n\t\t\t|| this.checkString('-lh5-', {offset: 2})\n\t\t\t|| this.checkString('-lh6-', {offset: 2})\n\t\t\t|| this.checkString('-lh7-', {offset: 2})\n\t\t\t|| this.checkString('-lzs-', {offset: 2})\n\t\t\t|| this.checkString('-lz4-', {offset: 2})\n\t\t\t|| this.checkString('-lz5-', {offset: 2})\n\t\t\t|| this.checkString('-lhd-', {offset: 2})\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'lzh',\n\t\t\t\tmime: 'application/x-lzh-compressed',\n\t\t\t};\n\t\t}\n\n\t\t// MPEG program stream (PS or MPEG-PS)\n\t\tif (this.check([0x00, 0x00, 0x01, 0xBA])) {\n\t\t\t//  MPEG-PS, MPEG-1 Part 1\n\t\t\tif (this.check([0x21], {offset: 4, mask: [0xF1]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mpg', // May also be .ps, .mpeg\n\t\t\t\t\tmime: 'video/MP1S',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// MPEG-PS, MPEG-2 Part 1\n\t\t\tif (this.check([0x44], {offset: 4, mask: [0xC4]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mpg', // May also be .mpg, .m2p, .vob or .sub\n\t\t\t\t\tmime: 'video/MP2P',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\tif (this.checkString('ITSF')) {\n\t\t\treturn {\n\t\t\t\text: 'chm',\n\t\t\t\tmime: 'application/vnd.ms-htmlhelp',\n\t\t\t};\n\t\t}\n\n\t\t// -- 6-byte signatures --\n\n\t\tif (this.check([0xFD, 0x37, 0x7A, 0x58, 0x5A, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'xz',\n\t\t\t\tmime: 'application/x-xz',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('<?xml ')) {\n\t\t\treturn {\n\t\t\t\text: 'xml',\n\t\t\t\tmime: 'application/xml',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x37, 0x7A, 0xBC, 0xAF, 0x27, 0x1C])) {\n\t\t\treturn {\n\t\t\t\text: '7z',\n\t\t\t\tmime: 'application/x-7z-compressed',\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x52, 0x61, 0x72, 0x21, 0x1A, 0x7])\n\t\t\t&& (this.buffer[6] === 0x0 || this.buffer[6] === 0x1)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'rar',\n\t\t\t\tmime: 'application/x-rar-compressed',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('solid ')) {\n\t\t\treturn {\n\t\t\t\text: 'stl',\n\t\t\t\tmime: 'model/stl',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('AC')) {\n\t\t\tconst version = this.buffer.toString('binary', 2, 6);\n\t\t\tif (version.match('^d*') && version >= 1000 && version <= 1050) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'dwg',\n\t\t\t\t\tmime: 'image/vnd.dwg',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\t// -- 7-byte signatures --\n\n\t\tif (this.checkString('BLENDER')) {\n\t\t\treturn {\n\t\t\t\text: 'blend',\n\t\t\t\tmime: 'application/x-blender',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('!<arch>')) {\n\t\t\tawait tokenizer.ignore(8);\n\t\t\tconst string = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(13, 'ascii'));\n\t\t\tif (string === 'debian-binary') {\n\t\t\t\treturn {\n\t\t\t\t\text: 'deb',\n\t\t\t\t\tmime: 'application/x-deb',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn {\n\t\t\t\text: 'ar',\n\t\t\t\tmime: 'application/x-unix-archive',\n\t\t\t};\n\t\t}\n\n\t\t// -- 8-byte signatures --\n\n\t\tif (this.check([0x89, 0x50, 0x4E, 0x47, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\t\t// APNG format (https://wiki.mozilla.org/APNG_Specification)\n\t\t\t// 1. Find the first IDAT (image data) chunk (49 44 41 54)\n\t\t\t// 2. Check if there is an \"acTL\" chunk before the IDAT one (61 63 54 4C)\n\n\t\t\t// Offset calculated as follows:\n\t\t\t// - 8 bytes: PNG signature\n\t\t\t// - 4 (length) + 4 (chunk type) + 13 (chunk data) + 4 (CRC): IHDR chunk\n\n\t\t\tawait tokenizer.ignore(8); // ignore PNG signature\n\n\t\t\tasync function readChunkHeader() {\n\t\t\t\treturn {\n\t\t\t\t\tlength: await tokenizer.readToken(token_types__WEBPACK_IMPORTED_MODULE_1__.INT32_BE),\n\t\t\t\t\ttype: await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(4, 'binary')),\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tdo {\n\t\t\t\tconst chunk = await readChunkHeader();\n\t\t\t\tif (chunk.length < 0) {\n\t\t\t\t\treturn; // Invalid chunk length\n\t\t\t\t}\n\n\t\t\t\tswitch (chunk.type) {\n\t\t\t\t\tcase 'IDAT':\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'png',\n\t\t\t\t\t\t\tmime: 'image/png',\n\t\t\t\t\t\t};\n\t\t\t\t\tcase 'acTL':\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'apng',\n\t\t\t\t\t\t\tmime: 'image/apng',\n\t\t\t\t\t\t};\n\t\t\t\t\tdefault:\n\t\t\t\t\t\tawait tokenizer.ignore(chunk.length + 4); // Ignore chunk-data + CRC\n\t\t\t\t}\n\t\t\t} while (tokenizer.position + 8 < tokenizer.fileInfo.size);\n\n\t\t\treturn {\n\t\t\t\text: 'png',\n\t\t\t\tmime: 'image/png',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x41, 0x52, 0x52, 0x4F, 0x57, 0x31, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'arrow',\n\t\t\t\tmime: 'application/x-apache-arrow',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x67, 0x6C, 0x54, 0x46, 0x02, 0x00, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'glb',\n\t\t\t\tmime: 'model/gltf-binary',\n\t\t\t};\n\t\t}\n\n\t\t// `mov` format variants\n\t\tif (\n\t\t\tthis.check([0x66, 0x72, 0x65, 0x65], {offset: 4}) // `free`\n\t\t\t|| this.check([0x6D, 0x64, 0x61, 0x74], {offset: 4}) // `mdat` MJPEG\n\t\t\t|| this.check([0x6D, 0x6F, 0x6F, 0x76], {offset: 4}) // `moov`\n\t\t\t|| this.check([0x77, 0x69, 0x64, 0x65], {offset: 4}) // `wide`\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'mov',\n\t\t\t\tmime: 'video/quicktime',\n\t\t\t};\n\t\t}\n\n\t\t// -- 9-byte signatures --\n\n\t\tif (this.check([0x49, 0x49, 0x52, 0x4F, 0x08, 0x00, 0x00, 0x00, 0x18])) {\n\t\t\treturn {\n\t\t\t\text: 'orf',\n\t\t\t\tmime: 'image/x-olympus-orf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('gimp xcf ')) {\n\t\t\treturn {\n\t\t\t\text: 'xcf',\n\t\t\t\tmime: 'image/x-xcf',\n\t\t\t};\n\t\t}\n\n\t\t// -- 12-byte signatures --\n\n\t\tif (this.check([0x49, 0x49, 0x55, 0x00, 0x18, 0x00, 0x00, 0x00, 0x88, 0xE7, 0x74, 0xD8])) {\n\t\t\treturn {\n\t\t\t\text: 'rw2',\n\t\t\t\tmime: 'image/x-panasonic-rw2',\n\t\t\t};\n\t\t}\n\n\t\t// ASF_Header_Object first 80 bytes\n\t\tif (this.check([0x30, 0x26, 0xB2, 0x75, 0x8E, 0x66, 0xCF, 0x11, 0xA6, 0xD9])) {\n\t\t\tasync function readHeader() {\n\t\t\t\tconst guid = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(16);\n\t\t\t\tawait tokenizer.readBuffer(guid);\n\t\t\t\treturn {\n\t\t\t\t\tid: guid,\n\t\t\t\t\tsize: Number(await tokenizer.readToken(token_types__WEBPACK_IMPORTED_MODULE_1__.UINT64_LE)),\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tawait tokenizer.ignore(30);\n\t\t\t// Search for header should be in first 1KB of file.\n\t\t\twhile (tokenizer.position + 24 < tokenizer.fileInfo.size) {\n\t\t\t\tconst header = await readHeader();\n\t\t\t\tlet payload = header.size - 24;\n\t\t\t\tif (_check(header.id, [0x91, 0x07, 0xDC, 0xB7, 0xB7, 0xA9, 0xCF, 0x11, 0x8E, 0xE6, 0x00, 0xC0, 0x0C, 0x20, 0x53, 0x65])) {\n\t\t\t\t\t// Sync on Stream-Properties-Object (B7DC0791-A9B7-11CF-8EE6-00C00C205365)\n\t\t\t\t\tconst typeId = node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(16);\n\t\t\t\t\tpayload -= await tokenizer.readBuffer(typeId);\n\n\t\t\t\t\tif (_check(typeId, [0x40, 0x9E, 0x69, 0xF8, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {\n\t\t\t\t\t\t// Found audio:\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'asf',\n\t\t\t\t\t\t\tmime: 'audio/x-ms-asf',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tif (_check(typeId, [0xC0, 0xEF, 0x19, 0xBC, 0x4D, 0x5B, 0xCF, 0x11, 0xA8, 0xFD, 0x00, 0x80, 0x5F, 0x5C, 0x44, 0x2B])) {\n\t\t\t\t\t\t// Found video:\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'asf',\n\t\t\t\t\t\t\tmime: 'video/x-ms-asf',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\n\t\t\t\t\tbreak;\n\t\t\t\t}\n\n\t\t\t\tawait tokenizer.ignore(payload);\n\t\t\t}\n\n\t\t\t// Default to ASF generic extension\n\t\t\treturn {\n\t\t\t\text: 'asf',\n\t\t\t\tmime: 'application/vnd.ms-asf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xAB, 0x4B, 0x54, 0x58, 0x20, 0x31, 0x31, 0xBB, 0x0D, 0x0A, 0x1A, 0x0A])) {\n\t\t\treturn {\n\t\t\t\text: 'ktx',\n\t\t\t\tmime: 'image/ktx',\n\t\t\t};\n\t\t}\n\n\t\tif ((this.check([0x7E, 0x10, 0x04]) || this.check([0x7E, 0x18, 0x04])) && this.check([0x30, 0x4D, 0x49, 0x45], {offset: 4})) {\n\t\t\treturn {\n\t\t\t\text: 'mie',\n\t\t\t\tmime: 'application/x-mie',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x27, 0x0A, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00], {offset: 2})) {\n\t\t\treturn {\n\t\t\t\text: 'shp',\n\t\t\t\tmime: 'application/x-esri-shape',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x00, 0x00, 0x0C, 0x6A, 0x50, 0x20, 0x20, 0x0D, 0x0A, 0x87, 0x0A])) {\n\t\t\t// JPEG-2000 family\n\n\t\t\tawait tokenizer.ignore(20);\n\t\t\tconst type = await tokenizer.readToken(new token_types__WEBPACK_IMPORTED_MODULE_1__.StringType(4, 'ascii'));\n\t\t\tswitch (type) {\n\t\t\t\tcase 'jp2 ':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'jp2',\n\t\t\t\t\t\tmime: 'image/jp2',\n\t\t\t\t\t};\n\t\t\t\tcase 'jpx ':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'jpx',\n\t\t\t\t\t\tmime: 'image/jpx',\n\t\t\t\t\t};\n\t\t\t\tcase 'jpm ':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'jpm',\n\t\t\t\t\t\tmime: 'image/jpm',\n\t\t\t\t\t};\n\t\t\t\tcase 'mjp2':\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'mj2',\n\t\t\t\t\t\tmime: 'image/mj2',\n\t\t\t\t\t};\n\t\t\t\tdefault:\n\t\t\t\t\treturn;\n\t\t\t}\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0xFF, 0x0A])\n\t\t\t|| this.check([0x00, 0x00, 0x00, 0x0C, 0x4A, 0x58, 0x4C, 0x20, 0x0D, 0x0A, 0x87, 0x0A])\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'jxl',\n\t\t\t\tmime: 'image/jxl',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xFE, 0xFF])) { // UTF-16-BOM-LE\n\t\t\tif (this.check([0, 60, 0, 63, 0, 120, 0, 109, 0, 108], {offset: 2})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'xml',\n\t\t\t\t\tmime: 'application/xml',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn undefined; // Some unknown text based format\n\t\t}\n\n\t\t// -- Unsafe signatures --\n\n\t\tif (\n\t\t\tthis.check([0x0, 0x0, 0x1, 0xBA])\n\t\t\t|| this.check([0x0, 0x0, 0x1, 0xB3])\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'mpg',\n\t\t\t\tmime: 'video/mpeg',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x01, 0x00, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'ttf',\n\t\t\t\tmime: 'font/ttf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x00, 0x01, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'ico',\n\t\t\t\tmime: 'image/x-icon',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x00, 0x00, 0x02, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'cur',\n\t\t\t\tmime: 'image/x-icon',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xD0, 0xCF, 0x11, 0xE0, 0xA1, 0xB1, 0x1A, 0xE1])) {\n\t\t\t// Detected Microsoft Compound File Binary File (MS-CFB) Format.\n\t\t\treturn {\n\t\t\t\text: 'cfb',\n\t\t\t\tmime: 'application/x-cfb',\n\t\t\t};\n\t\t}\n\n\t\t// Increase sample size from 12 to 256.\n\t\tawait tokenizer.peekBuffer(this.buffer, {length: Math.min(256, tokenizer.fileInfo.size), mayBeLess: true});\n\n\t\t// -- 15-byte signatures --\n\n\t\tif (this.checkString('BEGIN:')) {\n\t\t\tif (this.checkString('VCARD', {offset: 6})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'vcf',\n\t\t\t\t\tmime: 'text/vcard',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (this.checkString('VCALENDAR', {offset: 6})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'ics',\n\t\t\t\t\tmime: 'text/calendar',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\n\t\t// `raf` is here just to keep all the raw image detectors together.\n\t\tif (this.checkString('FUJIFILMCCD-RAW')) {\n\t\t\treturn {\n\t\t\t\text: 'raf',\n\t\t\t\tmime: 'image/x-fujifilm-raf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('Extended Module:')) {\n\t\t\treturn {\n\t\t\t\text: 'xm',\n\t\t\t\tmime: 'audio/x-xm',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('Creative Voice File')) {\n\t\t\treturn {\n\t\t\t\text: 'voc',\n\t\t\t\tmime: 'audio/x-voc',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x04, 0x00, 0x00, 0x00]) && this.buffer.length >= 16) { // Rough & quick check Pickle/ASAR\n\t\t\tconst jsonSize = this.buffer.readUInt32LE(12);\n\t\t\tif (jsonSize > 12 && this.buffer.length >= jsonSize + 16) {\n\t\t\t\ttry {\n\t\t\t\t\tconst header = this.buffer.slice(16, jsonSize + 16).toString();\n\t\t\t\t\tconst json = JSON.parse(header);\n\t\t\t\t\t// Check if Pickle is ASAR\n\t\t\t\t\tif (json.files) { // Final check, assuring Pickle/ASAR format\n\t\t\t\t\t\treturn {\n\t\t\t\t\t\t\text: 'asar',\n\t\t\t\t\t\t\tmime: 'application/x-asar',\n\t\t\t\t\t\t};\n\t\t\t\t\t}\n\t\t\t\t} catch {}\n\t\t\t}\n\t\t}\n\n\t\tif (this.check([0x06, 0x0E, 0x2B, 0x34, 0x02, 0x05, 0x01, 0x01, 0x0D, 0x01, 0x02, 0x01, 0x01, 0x02])) {\n\t\t\treturn {\n\t\t\t\text: 'mxf',\n\t\t\t\tmime: 'application/mxf',\n\t\t\t};\n\t\t}\n\n\t\tif (this.checkString('SCRM', {offset: 44})) {\n\t\t\treturn {\n\t\t\t\text: 's3m',\n\t\t\t\tmime: 'audio/x-s3m',\n\t\t\t};\n\t\t}\n\n\t\t// Raw MPEG-2 transport stream (188-byte packets)\n\t\tif (this.check([0x47]) && this.check([0x47], {offset: 188})) {\n\t\t\treturn {\n\t\t\t\text: 'mts',\n\t\t\t\tmime: 'video/mp2t',\n\t\t\t};\n\t\t}\n\n\t\t// Blu-ray Disc Audio-Video (BDAV) MPEG-2 transport stream has 4-byte TP_extra_header before each 188-byte packet\n\t\tif (this.check([0x47], {offset: 4}) && this.check([0x47], {offset: 196})) {\n\t\t\treturn {\n\t\t\t\text: 'mts',\n\t\t\t\tmime: 'video/mp2t',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x42, 0x4F, 0x4F, 0x4B, 0x4D, 0x4F, 0x42, 0x49], {offset: 60})) {\n\t\t\treturn {\n\t\t\t\text: 'mobi',\n\t\t\t\tmime: 'application/x-mobipocket-ebook',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x44, 0x49, 0x43, 0x4D], {offset: 128})) {\n\t\t\treturn {\n\t\t\t\text: 'dcm',\n\t\t\t\tmime: 'application/dicom',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x4C, 0x00, 0x00, 0x00, 0x01, 0x14, 0x02, 0x00, 0x00, 0x00, 0x00, 0x00, 0xC0, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x46])) {\n\t\t\treturn {\n\t\t\t\text: 'lnk',\n\t\t\t\tmime: 'application/x.ms.shortcut', // Invented by us\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x62, 0x6F, 0x6F, 0x6B, 0x00, 0x00, 0x00, 0x00, 0x6D, 0x61, 0x72, 0x6B, 0x00, 0x00, 0x00, 0x00])) {\n\t\t\treturn {\n\t\t\t\text: 'alias',\n\t\t\t\tmime: 'application/x.apple.alias', // Invented by us\n\t\t\t};\n\t\t}\n\n\t\tif (\n\t\t\tthis.check([0x4C, 0x50], {offset: 34})\n\t\t\t&& (\n\t\t\t\tthis.check([0x00, 0x00, 0x01], {offset: 8})\n\t\t\t\t|| this.check([0x01, 0x00, 0x02], {offset: 8})\n\t\t\t\t|| this.check([0x02, 0x00, 0x02], {offset: 8})\n\t\t\t)\n\t\t) {\n\t\t\treturn {\n\t\t\t\text: 'eot',\n\t\t\t\tmime: 'application/vnd.ms-fontobject',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0x06, 0x06, 0xED, 0xF5, 0xD8, 0x1D, 0x46, 0xE5, 0xBD, 0x31, 0xEF, 0xE7, 0xFE, 0x74, 0xB7, 0x1D])) {\n\t\t\treturn {\n\t\t\t\text: 'indd',\n\t\t\t\tmime: 'application/x-indesign',\n\t\t\t};\n\t\t}\n\n\t\t// Increase sample size from 256 to 512\n\t\tawait tokenizer.peekBuffer(this.buffer, {length: Math.min(512, tokenizer.fileInfo.size), mayBeLess: true});\n\n\t\t// Requires a buffer size of 512 bytes\n\t\tif ((0,_util_js__WEBPACK_IMPORTED_MODULE_3__.tarHeaderChecksumMatches)(this.buffer)) {\n\t\t\treturn {\n\t\t\t\text: 'tar',\n\t\t\t\tmime: 'application/x-tar',\n\t\t\t};\n\t\t}\n\n\t\tif (this.check([0xFF, 0xFE])) { // UTF-16-BOM-BE\n\t\t\tif (this.check([60, 0, 63, 0, 120, 0, 109, 0, 108, 0], {offset: 2})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'xml',\n\t\t\t\t\tmime: 'application/xml',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\tif (this.check([0xFF, 0x0E, 0x53, 0x00, 0x6B, 0x00, 0x65, 0x00, 0x74, 0x00, 0x63, 0x00, 0x68, 0x00, 0x55, 0x00, 0x70, 0x00, 0x20, 0x00, 0x4D, 0x00, 0x6F, 0x00, 0x64, 0x00, 0x65, 0x00, 0x6C, 0x00], {offset: 2})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'skp',\n\t\t\t\t\tmime: 'application/vnd.sketchup.skp',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\treturn undefined; // Some text based format\n\t\t}\n\n\t\tif (this.checkString('-----BEGIN PGP MESSAGE-----')) {\n\t\t\treturn {\n\t\t\t\text: 'pgp',\n\t\t\t\tmime: 'application/pgp-encrypted',\n\t\t\t};\n\t\t}\n\n\t\t// Check MPEG 1 or 2 Layer 3 header, or 'layer 0' for ADTS (MPEG sync-word 0xFFE)\n\t\tif (this.buffer.length >= 2 && this.check([0xFF, 0xE0], {offset: 0, mask: [0xFF, 0xE0]})) {\n\t\t\tif (this.check([0x10], {offset: 1, mask: [0x16]})) {\n\t\t\t\t// Check for (ADTS) MPEG-2\n\t\t\t\tif (this.check([0x08], {offset: 1, mask: [0x08]})) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'aac',\n\t\t\t\t\t\tmime: 'audio/aac',\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\t// Must be (ADTS) MPEG-4\n\t\t\t\treturn {\n\t\t\t\t\text: 'aac',\n\t\t\t\t\tmime: 'audio/aac',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// MPEG 1 or 2 Layer 3 header\n\t\t\t// Check for MPEG layer 3\n\t\t\tif (this.check([0x02], {offset: 1, mask: [0x06]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp3',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Check for MPEG layer 2\n\t\t\tif (this.check([0x04], {offset: 1, mask: [0x06]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp2',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\n\t\t\t// Check for MPEG layer 1\n\t\t\tif (this.check([0x06], {offset: 1, mask: [0x06]})) {\n\t\t\t\treturn {\n\t\t\t\t\text: 'mp1',\n\t\t\t\t\tmime: 'audio/mpeg',\n\t\t\t\t};\n\t\t\t}\n\t\t}\n\t}\n\n\tasync readTiffTag(bigEndian) {\n\t\tconst tagId = await this.tokenizer.readToken(bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_LE);\n\t\tthis.tokenizer.ignore(10);\n\t\tswitch (tagId) {\n\t\t\tcase 50_341:\n\t\t\t\treturn {\n\t\t\t\t\text: 'arw',\n\t\t\t\t\tmime: 'image/x-sony-arw',\n\t\t\t\t};\n\t\t\tcase 50_706:\n\t\t\t\treturn {\n\t\t\t\t\text: 'dng',\n\t\t\t\t\tmime: 'image/x-adobe-dng',\n\t\t\t\t};\n\t\t\tdefault:\n\t\t}\n\t}\n\n\tasync readTiffIFD(bigEndian) {\n\t\tconst numberOfTags = await this.tokenizer.readToken(bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_LE);\n\t\tfor (let n = 0; n < numberOfTags; ++n) {\n\t\t\tconst fileType = await this.readTiffTag(bigEndian);\n\t\t\tif (fileType) {\n\t\t\t\treturn fileType;\n\t\t\t}\n\t\t}\n\t}\n\n\tasync readTiffHeader(bigEndian) {\n\t\tconst version = (bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT16_LE).get(this.buffer, 2);\n\t\tconst ifdOffset = (bigEndian ? token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_BE : token_types__WEBPACK_IMPORTED_MODULE_1__.UINT32_LE).get(this.buffer, 4);\n\n\t\tif (version === 42) {\n\t\t\t// TIFF file header\n\t\t\tif (ifdOffset >= 6) {\n\t\t\t\tif (this.checkString('CR', {offset: 8})) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'cr2',\n\t\t\t\t\t\tmime: 'image/x-canon-cr2',\n\t\t\t\t\t};\n\t\t\t\t}\n\n\t\t\t\tif (ifdOffset >= 8 && (this.check([0x1C, 0x00, 0xFE, 0x00], {offset: 8}) || this.check([0x1F, 0x00, 0x0B, 0x00], {offset: 8}))) {\n\t\t\t\t\treturn {\n\t\t\t\t\t\text: 'nef',\n\t\t\t\t\t\tmime: 'image/x-nikon-nef',\n\t\t\t\t\t};\n\t\t\t\t}\n\t\t\t}\n\n\t\t\tawait this.tokenizer.ignore(ifdOffset);\n\t\t\tconst fileType = await this.readTiffIFD(bigEndian);\n\t\t\treturn fileType ?? {\n\t\t\t\text: 'tif',\n\t\t\t\tmime: 'image/tiff',\n\t\t\t};\n\t\t}\n\n\t\tif (version === 43) {\t// Big TIFF file header\n\t\t\treturn {\n\t\t\t\text: 'tif',\n\t\t\t\tmime: 'image/tiff',\n\t\t\t};\n\t\t}\n\t}\n}\n\nasync function fileTypeStream(readableStream, {sampleSize = minimumBytes} = {}) {\n\tconst {default: stream} = await __webpack_require__.e(/*! import() */ \"node_stream\").then(__webpack_require__.t.bind(__webpack_require__, /*! node:stream */ \"node:stream\", 19));\n\n\treturn new Promise((resolve, reject) => {\n\t\treadableStream.on('error', reject);\n\n\t\treadableStream.once('readable', () => {\n\t\t\t(async () => {\n\t\t\t\ttry {\n\t\t\t\t\t// Set up output stream\n\t\t\t\t\tconst pass = new stream.PassThrough();\n\t\t\t\t\tconst outputStream = stream.pipeline ? stream.pipeline(readableStream, pass, () => {}) : readableStream.pipe(pass);\n\n\t\t\t\t\t// Read the input stream and detect the filetype\n\t\t\t\t\tconst chunk = readableStream.read(sampleSize) ?? readableStream.read() ?? node_buffer__WEBPACK_IMPORTED_MODULE_0__.Buffer.alloc(0);\n\t\t\t\t\ttry {\n\t\t\t\t\t\tconst fileType = await fileTypeFromBuffer(chunk);\n\t\t\t\t\t\tpass.fileType = fileType;\n\t\t\t\t\t} catch (error) {\n\t\t\t\t\t\tif (error instanceof strtok3_core__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError) {\n\t\t\t\t\t\t\tpass.fileType = undefined;\n\t\t\t\t\t\t} else {\n\t\t\t\t\t\t\treject(error);\n\t\t\t\t\t\t}\n\t\t\t\t\t}\n\n\t\t\t\t\tresolve(outputStream);\n\t\t\t\t} catch (error) {\n\t\t\t\t\treject(error);\n\t\t\t\t}\n\t\t\t})();\n\t\t});\n\t});\n}\n\nconst supportedExtensions = new Set(_supported_js__WEBPACK_IMPORTED_MODULE_4__.extensions);\nconst supportedMimeTypes = new Set(_supported_js__WEBPACK_IMPORTED_MODULE_4__.mimeTypes);\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/file-type/core.js?");

/***/ }),

/***/ "./node_modules/file-type/supported.js":
/*!*********************************************!*\
  !*** ./node_modules/file-type/supported.js ***!
  \*********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"extensions\": () => (/* binding */ extensions),\n/* harmony export */   \"mimeTypes\": () => (/* binding */ mimeTypes)\n/* harmony export */ });\nconst extensions = [\n\t'jpg',\n\t'png',\n\t'apng',\n\t'gif',\n\t'webp',\n\t'flif',\n\t'xcf',\n\t'cr2',\n\t'cr3',\n\t'orf',\n\t'arw',\n\t'dng',\n\t'nef',\n\t'rw2',\n\t'raf',\n\t'tif',\n\t'bmp',\n\t'icns',\n\t'jxr',\n\t'psd',\n\t'indd',\n\t'zip',\n\t'tar',\n\t'rar',\n\t'gz',\n\t'bz2',\n\t'7z',\n\t'dmg',\n\t'mp4',\n\t'mid',\n\t'mkv',\n\t'webm',\n\t'mov',\n\t'avi',\n\t'mpg',\n\t'mp2',\n\t'mp3',\n\t'm4a',\n\t'oga',\n\t'ogg',\n\t'ogv',\n\t'opus',\n\t'flac',\n\t'wav',\n\t'spx',\n\t'amr',\n\t'pdf',\n\t'epub',\n\t'elf',\n\t'exe',\n\t'swf',\n\t'rtf',\n\t'wasm',\n\t'woff',\n\t'woff2',\n\t'eot',\n\t'ttf',\n\t'otf',\n\t'ico',\n\t'flv',\n\t'ps',\n\t'xz',\n\t'sqlite',\n\t'nes',\n\t'crx',\n\t'xpi',\n\t'cab',\n\t'deb',\n\t'ar',\n\t'rpm',\n\t'Z',\n\t'lz',\n\t'cfb',\n\t'mxf',\n\t'mts',\n\t'blend',\n\t'bpg',\n\t'docx',\n\t'pptx',\n\t'xlsx',\n\t'3gp',\n\t'3g2',\n\t'jp2',\n\t'jpm',\n\t'jpx',\n\t'mj2',\n\t'aif',\n\t'qcp',\n\t'odt',\n\t'ods',\n\t'odp',\n\t'xml',\n\t'mobi',\n\t'heic',\n\t'cur',\n\t'ktx',\n\t'ape',\n\t'wv',\n\t'dcm',\n\t'ics',\n\t'glb',\n\t'pcap',\n\t'dsf',\n\t'lnk',\n\t'alias',\n\t'voc',\n\t'ac3',\n\t'm4v',\n\t'm4p',\n\t'm4b',\n\t'f4v',\n\t'f4p',\n\t'f4b',\n\t'f4a',\n\t'mie',\n\t'asf',\n\t'ogm',\n\t'ogx',\n\t'mpc',\n\t'arrow',\n\t'shp',\n\t'aac',\n\t'mp1',\n\t'it',\n\t's3m',\n\t'xm',\n\t'ai',\n\t'skp',\n\t'avif',\n\t'eps',\n\t'lzh',\n\t'pgp',\n\t'asar',\n\t'stl',\n\t'chm',\n\t'3mf',\n\t'zst',\n\t'jxl',\n\t'vcf',\n\t'jls',\n\t'pst',\n\t'dwg',\n\t'parquet',\n];\n\nconst mimeTypes = [\n\t'image/jpeg',\n\t'image/png',\n\t'image/gif',\n\t'image/webp',\n\t'image/flif',\n\t'image/x-xcf',\n\t'image/x-canon-cr2',\n\t'image/x-canon-cr3',\n\t'image/tiff',\n\t'image/bmp',\n\t'image/vnd.ms-photo',\n\t'image/vnd.adobe.photoshop',\n\t'application/x-indesign',\n\t'application/epub+zip',\n\t'application/x-xpinstall',\n\t'application/vnd.oasis.opendocument.text',\n\t'application/vnd.oasis.opendocument.spreadsheet',\n\t'application/vnd.oasis.opendocument.presentation',\n\t'application/vnd.openxmlformats-officedocument.wordprocessingml.document',\n\t'application/vnd.openxmlformats-officedocument.presentationml.presentation',\n\t'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',\n\t'application/zip',\n\t'application/x-tar',\n\t'application/x-rar-compressed',\n\t'application/gzip',\n\t'application/x-bzip2',\n\t'application/x-7z-compressed',\n\t'application/x-apple-diskimage',\n\t'application/x-apache-arrow',\n\t'video/mp4',\n\t'audio/midi',\n\t'video/x-matroska',\n\t'video/webm',\n\t'video/quicktime',\n\t'video/vnd.avi',\n\t'audio/vnd.wave',\n\t'audio/qcelp',\n\t'audio/x-ms-asf',\n\t'video/x-ms-asf',\n\t'application/vnd.ms-asf',\n\t'video/mpeg',\n\t'video/3gpp',\n\t'audio/mpeg',\n\t'audio/mp4', // RFC 4337\n\t'audio/opus',\n\t'video/ogg',\n\t'audio/ogg',\n\t'application/ogg',\n\t'audio/x-flac',\n\t'audio/ape',\n\t'audio/wavpack',\n\t'audio/amr',\n\t'application/pdf',\n\t'application/x-elf',\n\t'application/x-msdownload',\n\t'application/x-shockwave-flash',\n\t'application/rtf',\n\t'application/wasm',\n\t'font/woff',\n\t'font/woff2',\n\t'application/vnd.ms-fontobject',\n\t'font/ttf',\n\t'font/otf',\n\t'image/x-icon',\n\t'video/x-flv',\n\t'application/postscript',\n\t'application/eps',\n\t'application/x-xz',\n\t'application/x-sqlite3',\n\t'application/x-nintendo-nes-rom',\n\t'application/x-google-chrome-extension',\n\t'application/vnd.ms-cab-compressed',\n\t'application/x-deb',\n\t'application/x-unix-archive',\n\t'application/x-rpm',\n\t'application/x-compress',\n\t'application/x-lzip',\n\t'application/x-cfb',\n\t'application/x-mie',\n\t'application/mxf',\n\t'video/mp2t',\n\t'application/x-blender',\n\t'image/bpg',\n\t'image/jp2',\n\t'image/jpx',\n\t'image/jpm',\n\t'image/mj2',\n\t'audio/aiff',\n\t'application/xml',\n\t'application/x-mobipocket-ebook',\n\t'image/heif',\n\t'image/heif-sequence',\n\t'image/heic',\n\t'image/heic-sequence',\n\t'image/icns',\n\t'image/ktx',\n\t'application/dicom',\n\t'audio/x-musepack',\n\t'text/calendar',\n\t'text/vcard',\n\t'model/gltf-binary',\n\t'application/vnd.tcpdump.pcap',\n\t'audio/x-dsf', // Non-standard\n\t'application/x.ms.shortcut', // Invented by us\n\t'application/x.apple.alias', // Invented by us\n\t'audio/x-voc',\n\t'audio/vnd.dolby.dd-raw',\n\t'audio/x-m4a',\n\t'image/apng',\n\t'image/x-olympus-orf',\n\t'image/x-sony-arw',\n\t'image/x-adobe-dng',\n\t'image/x-nikon-nef',\n\t'image/x-panasonic-rw2',\n\t'image/x-fujifilm-raf',\n\t'video/x-m4v',\n\t'video/3gpp2',\n\t'application/x-esri-shape',\n\t'audio/aac',\n\t'audio/x-it',\n\t'audio/x-s3m',\n\t'audio/x-xm',\n\t'video/MP1S',\n\t'video/MP2P',\n\t'application/vnd.sketchup.skp',\n\t'image/avif',\n\t'application/x-lzh-compressed',\n\t'application/pgp-encrypted',\n\t'application/x-asar',\n\t'model/stl',\n\t'application/vnd.ms-htmlhelp',\n\t'model/3mf',\n\t'image/jxl',\n\t'application/zstd',\n\t'image/jls',\n\t'application/vnd.ms-outlook',\n\t'image/vnd.dwg',\n\t'application/x-parquet',\n];\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/file-type/supported.js?");

/***/ }),

/***/ "./node_modules/file-type/util.js":
/*!****************************************!*\
  !*** ./node_modules/file-type/util.js ***!
  \****************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"stringToBytes\": () => (/* binding */ stringToBytes),\n/* harmony export */   \"tarHeaderChecksumMatches\": () => (/* binding */ tarHeaderChecksumMatches),\n/* harmony export */   \"uint32SyncSafeToken\": () => (/* binding */ uint32SyncSafeToken)\n/* harmony export */ });\nfunction stringToBytes(string) {\n\treturn [...string].map(character => character.charCodeAt(0)); // eslint-disable-line unicorn/prefer-code-point\n}\n\n/**\nChecks whether the TAR checksum is valid.\n\n@param {Buffer} buffer - The TAR header `[offset ... offset + 512]`.\n@param {number} offset - TAR header offset.\n@returns {boolean} `true` if the TAR checksum is valid, otherwise `false`.\n*/\nfunction tarHeaderChecksumMatches(buffer, offset = 0) {\n\tconst readSum = Number.parseInt(buffer.toString('utf8', 148, 154).replace(/\\0.*$/, '').trim(), 8); // Read sum in header\n\tif (Number.isNaN(readSum)) {\n\t\treturn false;\n\t}\n\n\tlet sum = 8 * 0x20; // Initialize signed bit sum\n\n\tfor (let index = offset; index < offset + 148; index++) {\n\t\tsum += buffer[index];\n\t}\n\n\tfor (let index = offset + 156; index < offset + 512; index++) {\n\t\tsum += buffer[index];\n\t}\n\n\treturn readSum === sum;\n}\n\n/**\nID3 UINT32 sync-safe tokenizer token.\n28 bits (representing up to 256MB) integer, the msb is 0 to avoid \"false syncsignals\".\n*/\nconst uint32SyncSafeToken = {\n\tget: (buffer, offset) => (buffer[offset + 3] & 0x7F) | ((buffer[offset + 2]) << 7) | ((buffer[offset + 1]) << 14) | ((buffer[offset]) << 21),\n\tlen: 4,\n};\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/file-type/util.js?");

/***/ }),

/***/ "./node_modules/peek-readable/lib/Deferred.js":
/*!****************************************************!*\
  !*** ./node_modules/peek-readable/lib/Deferred.js ***!
  \****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"Deferred\": () => (/* binding */ Deferred)\n/* harmony export */ });\nclass Deferred {\n    constructor() {\n        this.resolve = () => null;\n        this.reject = () => null;\n        this.promise = new Promise((resolve, reject) => {\n            this.reject = reject;\n            this.resolve = resolve;\n        });\n    }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/peek-readable/lib/Deferred.js?");

/***/ }),

/***/ "./node_modules/peek-readable/lib/EndOfFileStream.js":
/*!***********************************************************!*\
  !*** ./node_modules/peek-readable/lib/EndOfFileStream.js ***!
  \***********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* binding */ EndOfStreamError),\n/* harmony export */   \"defaultMessages\": () => (/* binding */ defaultMessages)\n/* harmony export */ });\nconst defaultMessages = 'End-Of-Stream';\n/**\n * Thrown on read operation of the end of file or stream has been reached\n */\nclass EndOfStreamError extends Error {\n    constructor() {\n        super(defaultMessages);\n    }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/peek-readable/lib/EndOfFileStream.js?");

/***/ }),

/***/ "./node_modules/peek-readable/lib/StreamReader.js":
/*!********************************************************!*\
  !*** ./node_modules/peek-readable/lib/StreamReader.js ***!
  \********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError),\n/* harmony export */   \"StreamReader\": () => (/* binding */ StreamReader)\n/* harmony export */ });\n/* harmony import */ var _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./EndOfFileStream.js */ \"./node_modules/peek-readable/lib/EndOfFileStream.js\");\n/* harmony import */ var _Deferred_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./Deferred.js */ \"./node_modules/peek-readable/lib/Deferred.js\");\n\n\n\nconst maxStreamReadSize = 1 * 1024 * 1024; // Maximum request length on read-stream operation\nclass StreamReader {\n    constructor(s) {\n        this.s = s;\n        /**\n         * Deferred used for postponed read request (as not data is yet available to read)\n         */\n        this.deferred = null;\n        this.endOfStream = false;\n        /**\n         * Store peeked data\n         * @type {Array}\n         */\n        this.peekQueue = [];\n        if (!s.read || !s.once) {\n            throw new Error('Expected an instance of stream.Readable');\n        }\n        this.s.once('end', () => this.reject(new _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError()));\n        this.s.once('error', err => this.reject(err));\n        this.s.once('close', () => this.reject(new Error('Stream closed')));\n    }\n    /**\n     * Read ahead (peek) from stream. Subsequent read or peeks will return the same data\n     * @param uint8Array - Uint8Array (or Buffer) to store data read from stream in\n     * @param offset - Offset target\n     * @param length - Number of bytes to read\n     * @returns Number of bytes peeked\n     */\n    async peek(uint8Array, offset, length) {\n        const bytesRead = await this.read(uint8Array, offset, length);\n        this.peekQueue.push(uint8Array.subarray(offset, offset + bytesRead)); // Put read data back to peek buffer\n        return bytesRead;\n    }\n    /**\n     * Read chunk from stream\n     * @param buffer - Target Uint8Array (or Buffer) to store data read from stream in\n     * @param offset - Offset target\n     * @param length - Number of bytes to read\n     * @returns Number of bytes read\n     */\n    async read(buffer, offset, length) {\n        if (length === 0) {\n            return 0;\n        }\n        if (this.peekQueue.length === 0 && this.endOfStream) {\n            throw new _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        }\n        let remaining = length;\n        let bytesRead = 0;\n        // consume peeked data first\n        while (this.peekQueue.length > 0 && remaining > 0) {\n            const peekData = this.peekQueue.pop(); // Front of queue\n            if (!peekData)\n                throw new Error('peekData should be defined');\n            const lenCopy = Math.min(peekData.length, remaining);\n            buffer.set(peekData.subarray(0, lenCopy), offset + bytesRead);\n            bytesRead += lenCopy;\n            remaining -= lenCopy;\n            if (lenCopy < peekData.length) {\n                // remainder back to queue\n                this.peekQueue.push(peekData.subarray(lenCopy));\n            }\n        }\n        // continue reading from stream if required\n        while (remaining > 0 && !this.endOfStream) {\n            const reqLen = Math.min(remaining, maxStreamReadSize);\n            const chunkLen = await this.readFromStream(buffer, offset + bytesRead, reqLen);\n            bytesRead += chunkLen;\n            if (chunkLen < reqLen)\n                break;\n            remaining -= chunkLen;\n        }\n        return bytesRead;\n    }\n    /**\n     * Read chunk from stream\n     * @param buffer Target Uint8Array (or Buffer) to store data read from stream in\n     * @param offset Offset target\n     * @param length Number of bytes to read\n     * @returns Number of bytes read\n     */\n    async readFromStream(buffer, offset, length) {\n        const readBuffer = this.s.read(length);\n        if (readBuffer) {\n            buffer.set(readBuffer, offset);\n            return readBuffer.length;\n        }\n        else {\n            const request = {\n                buffer,\n                offset,\n                length,\n                deferred: new _Deferred_js__WEBPACK_IMPORTED_MODULE_1__.Deferred()\n            };\n            this.deferred = request.deferred;\n            this.s.once('readable', () => {\n                this.readDeferred(request);\n            });\n            return request.deferred.promise;\n        }\n    }\n    /**\n     * Process deferred read request\n     * @param request Deferred read request\n     */\n    readDeferred(request) {\n        const readBuffer = this.s.read(request.length);\n        if (readBuffer) {\n            request.buffer.set(readBuffer, request.offset);\n            request.deferred.resolve(readBuffer.length);\n            this.deferred = null;\n        }\n        else {\n            this.s.once('readable', () => {\n                this.readDeferred(request);\n            });\n        }\n    }\n    reject(err) {\n        this.endOfStream = true;\n        if (this.deferred) {\n            this.deferred.reject(err);\n            this.deferred = null;\n        }\n    }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/peek-readable/lib/StreamReader.js?");

/***/ }),

/***/ "./node_modules/peek-readable/lib/index.js":
/*!*************************************************!*\
  !*** ./node_modules/peek-readable/lib/index.js ***!
  \*************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError),\n/* harmony export */   \"StreamReader\": () => (/* reexport safe */ _StreamReader_js__WEBPACK_IMPORTED_MODULE_1__.StreamReader)\n/* harmony export */ });\n/* harmony import */ var _EndOfFileStream_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./EndOfFileStream.js */ \"./node_modules/peek-readable/lib/EndOfFileStream.js\");\n/* harmony import */ var _StreamReader_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./StreamReader.js */ \"./node_modules/peek-readable/lib/StreamReader.js\");\n\n\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/peek-readable/lib/index.js?");

/***/ }),

/***/ "./node_modules/strtok3/lib/AbstractTokenizer.js":
/*!*******************************************************!*\
  !*** ./node_modules/strtok3/lib/AbstractTokenizer.js ***!
  \*******************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AbstractTokenizer\": () => (/* binding */ AbstractTokenizer)\n/* harmony export */ });\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! peek-readable */ \"./node_modules/peek-readable/lib/index.js\");\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n\n\n/**\n * Core tokenizer\n */\nclass AbstractTokenizer {\n    constructor(fileInfo) {\n        /**\n         * Tokenizer-stream position\n         */\n        this.position = 0;\n        this.numBuffer = new Uint8Array(8);\n        this.fileInfo = fileInfo ? fileInfo : {};\n    }\n    /**\n     * Read a token from the tokenizer-stream\n     * @param token - The token to read\n     * @param position - If provided, the desired position in the tokenizer-stream\n     * @returns Promise with token data\n     */\n    async readToken(token, position = this.position) {\n        const uint8Array = node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.alloc(token.len);\n        const len = await this.readBuffer(uint8Array, { position });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(uint8Array, 0);\n    }\n    /**\n     * Peek a token from the tokenizer-stream.\n     * @param token - Token to peek from the tokenizer-stream.\n     * @param position - Offset where to begin reading within the file. If position is null, data will be read from the current file position.\n     * @returns Promise with token data\n     */\n    async peekToken(token, position = this.position) {\n        const uint8Array = node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.alloc(token.len);\n        const len = await this.peekBuffer(uint8Array, { position });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(uint8Array, 0);\n    }\n    /**\n     * Read a numeric token from the stream\n     * @param token - Numeric token\n     * @returns Promise with number\n     */\n    async readNumber(token) {\n        const len = await this.readBuffer(this.numBuffer, { length: token.len });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(this.numBuffer, 0);\n    }\n    /**\n     * Read a numeric token from the stream\n     * @param token - Numeric token\n     * @returns Promise with number\n     */\n    async peekNumber(token) {\n        const len = await this.peekBuffer(this.numBuffer, { length: token.len });\n        if (len < token.len)\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        return token.get(this.numBuffer, 0);\n    }\n    /**\n     * Ignore number of bytes, advances the pointer in under tokenizer-stream.\n     * @param length - Number of bytes to ignore\n     * @return resolves the number of bytes ignored, equals length if this available, otherwise the number of bytes available\n     */\n    async ignore(length) {\n        if (this.fileInfo.size !== undefined) {\n            const bytesLeft = this.fileInfo.size - this.position;\n            if (length > bytesLeft) {\n                this.position += bytesLeft;\n                return bytesLeft;\n            }\n        }\n        this.position += length;\n        return length;\n    }\n    async close() {\n        // empty\n    }\n    normalizeOptions(uint8Array, options) {\n        if (options && options.position !== undefined && options.position < this.position) {\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n        if (options) {\n            return {\n                mayBeLess: options.mayBeLess === true,\n                offset: options.offset ? options.offset : 0,\n                length: options.length ? options.length : (uint8Array.length - (options.offset ? options.offset : 0)),\n                position: options.position ? options.position : this.position\n            };\n        }\n        return {\n            mayBeLess: false,\n            offset: 0,\n            length: uint8Array.length,\n            position: this.position\n        };\n    }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/strtok3/lib/AbstractTokenizer.js?");

/***/ }),

/***/ "./node_modules/strtok3/lib/BufferTokenizer.js":
/*!*****************************************************!*\
  !*** ./node_modules/strtok3/lib/BufferTokenizer.js ***!
  \*****************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"BufferTokenizer\": () => (/* binding */ BufferTokenizer)\n/* harmony export */ });\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! peek-readable */ \"./node_modules/peek-readable/lib/index.js\");\n/* harmony import */ var _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./AbstractTokenizer.js */ \"./node_modules/strtok3/lib/AbstractTokenizer.js\");\n\n\nclass BufferTokenizer extends _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_1__.AbstractTokenizer {\n    /**\n     * Construct BufferTokenizer\n     * @param uint8Array - Uint8Array to tokenize\n     * @param fileInfo - Pass additional file information to the tokenizer\n     */\n    constructor(uint8Array, fileInfo) {\n        super(fileInfo);\n        this.uint8Array = uint8Array;\n        this.fileInfo.size = this.fileInfo.size ? this.fileInfo.size : uint8Array.length;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param uint8Array - Uint8Array to tokenize\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async readBuffer(uint8Array, options) {\n        if (options && options.position) {\n            if (options.position < this.position) {\n                throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n            }\n            this.position = options.position;\n        }\n        const bytesRead = await this.peekBuffer(uint8Array, options);\n        this.position += bytesRead;\n        return bytesRead;\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param uint8Array\n     * @param options - Read behaviour options\n     * @returns {Promise<number>}\n     */\n    async peekBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        const bytes2read = Math.min(this.uint8Array.length - normOptions.position, normOptions.length);\n        if ((!normOptions.mayBeLess) && bytes2read < normOptions.length) {\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_0__.EndOfStreamError();\n        }\n        else {\n            uint8Array.set(this.uint8Array.subarray(normOptions.position, normOptions.position + bytes2read), normOptions.offset);\n            return bytes2read;\n        }\n    }\n    async close() {\n        // empty\n    }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/strtok3/lib/BufferTokenizer.js?");

/***/ }),

/***/ "./node_modules/strtok3/lib/ReadStreamTokenizer.js":
/*!*********************************************************!*\
  !*** ./node_modules/strtok3/lib/ReadStreamTokenizer.js ***!
  \*********************************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"ReadStreamTokenizer\": () => (/* binding */ ReadStreamTokenizer)\n/* harmony export */ });\n/* harmony import */ var _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./AbstractTokenizer.js */ \"./node_modules/strtok3/lib/AbstractTokenizer.js\");\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! peek-readable */ \"./node_modules/peek-readable/lib/index.js\");\n\n\nconst maxBufferSize = 256000;\nclass ReadStreamTokenizer extends _AbstractTokenizer_js__WEBPACK_IMPORTED_MODULE_0__.AbstractTokenizer {\n    constructor(stream, fileInfo) {\n        super(fileInfo);\n        this.streamReader = new peek_readable__WEBPACK_IMPORTED_MODULE_1__.StreamReader(stream);\n    }\n    /**\n     * Get file information, an HTTP-client may implement this doing a HEAD request\n     * @return Promise with file information\n     */\n    async getFileInfo() {\n        return this.fileInfo;\n    }\n    /**\n     * Read buffer from tokenizer\n     * @param uint8Array - Target Uint8Array to fill with data read from the tokenizer-stream\n     * @param options - Read behaviour options\n     * @returns Promise with number of bytes read\n     */\n    async readBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        const skipBytes = normOptions.position - this.position;\n        if (skipBytes > 0) {\n            await this.ignore(skipBytes);\n            return this.readBuffer(uint8Array, options);\n        }\n        else if (skipBytes < 0) {\n            throw new Error('`options.position` must be equal or greater than `tokenizer.position`');\n        }\n        if (normOptions.length === 0) {\n            return 0;\n        }\n        const bytesRead = await this.streamReader.read(uint8Array, normOptions.offset, normOptions.length);\n        this.position += bytesRead;\n        if ((!options || !options.mayBeLess) && bytesRead < normOptions.length) {\n            throw new peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError();\n        }\n        return bytesRead;\n    }\n    /**\n     * Peek (read ahead) buffer from tokenizer\n     * @param uint8Array - Uint8Array (or Buffer) to write data to\n     * @param options - Read behaviour options\n     * @returns Promise with number of bytes peeked\n     */\n    async peekBuffer(uint8Array, options) {\n        const normOptions = this.normalizeOptions(uint8Array, options);\n        let bytesRead = 0;\n        if (normOptions.position) {\n            const skipBytes = normOptions.position - this.position;\n            if (skipBytes > 0) {\n                const skipBuffer = new Uint8Array(normOptions.length + skipBytes);\n                bytesRead = await this.peekBuffer(skipBuffer, { mayBeLess: normOptions.mayBeLess });\n                uint8Array.set(skipBuffer.subarray(skipBytes), normOptions.offset);\n                return bytesRead - skipBytes;\n            }\n            else if (skipBytes < 0) {\n                throw new Error('Cannot peek from a negative offset in a stream');\n            }\n        }\n        if (normOptions.length > 0) {\n            try {\n                bytesRead = await this.streamReader.peek(uint8Array, normOptions.offset, normOptions.length);\n            }\n            catch (err) {\n                if (options && options.mayBeLess && err instanceof peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError) {\n                    return 0;\n                }\n                throw err;\n            }\n            if ((!normOptions.mayBeLess) && bytesRead < normOptions.length) {\n                throw new peek_readable__WEBPACK_IMPORTED_MODULE_1__.EndOfStreamError();\n            }\n        }\n        return bytesRead;\n    }\n    async ignore(length) {\n        // debug(`ignore ${this.position}...${this.position + length - 1}`);\n        const bufSize = Math.min(maxBufferSize, length);\n        const buf = new Uint8Array(bufSize);\n        let totBytesRead = 0;\n        while (totBytesRead < length) {\n            const remaining = length - totBytesRead;\n            const bytesRead = await this.readBuffer(buf, { length: Math.min(bufSize, remaining) });\n            if (bytesRead < 0) {\n                return bytesRead;\n            }\n            totBytesRead += bytesRead;\n        }\n        return totBytesRead;\n    }\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/strtok3/lib/ReadStreamTokenizer.js?");

/***/ }),

/***/ "./node_modules/strtok3/lib/core.js":
/*!******************************************!*\
  !*** ./node_modules/strtok3/lib/core.js ***!
  \******************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"EndOfStreamError\": () => (/* reexport safe */ peek_readable__WEBPACK_IMPORTED_MODULE_2__.EndOfStreamError),\n/* harmony export */   \"fromBuffer\": () => (/* binding */ fromBuffer),\n/* harmony export */   \"fromStream\": () => (/* binding */ fromStream)\n/* harmony export */ });\n/* harmony import */ var _ReadStreamTokenizer_js__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ./ReadStreamTokenizer.js */ \"./node_modules/strtok3/lib/ReadStreamTokenizer.js\");\n/* harmony import */ var _BufferTokenizer_js__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! ./BufferTokenizer.js */ \"./node_modules/strtok3/lib/BufferTokenizer.js\");\n/* harmony import */ var peek_readable__WEBPACK_IMPORTED_MODULE_2__ = __webpack_require__(/*! peek-readable */ \"./node_modules/peek-readable/lib/index.js\");\n\n\n\n/**\n * Construct ReadStreamTokenizer from given Stream.\n * Will set fileSize, if provided given Stream has set the .path property/\n * @param stream - Read from Node.js Stream.Readable\n * @param fileInfo - Pass the file information, like size and MIME-type of the corresponding stream.\n * @returns ReadStreamTokenizer\n */\nfunction fromStream(stream, fileInfo) {\n    fileInfo = fileInfo ? fileInfo : {};\n    return new _ReadStreamTokenizer_js__WEBPACK_IMPORTED_MODULE_0__.ReadStreamTokenizer(stream, fileInfo);\n}\n/**\n * Construct ReadStreamTokenizer from given Buffer.\n * @param uint8Array - Uint8Array to tokenize\n * @param fileInfo - Pass additional file information to the tokenizer\n * @returns BufferTokenizer\n */\nfunction fromBuffer(uint8Array, fileInfo) {\n    return new _BufferTokenizer_js__WEBPACK_IMPORTED_MODULE_1__.BufferTokenizer(uint8Array, fileInfo);\n}\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/strtok3/lib/core.js?");

/***/ }),

/***/ "./node_modules/token-types/lib/index.js":
/*!***********************************************!*\
  !*** ./node_modules/token-types/lib/index.js ***!
  \***********************************************/
/***/ ((__unused_webpack___webpack_module__, __webpack_exports__, __webpack_require__) => {

"use strict";
eval("__webpack_require__.r(__webpack_exports__);\n/* harmony export */ __webpack_require__.d(__webpack_exports__, {\n/* harmony export */   \"AnsiStringType\": () => (/* binding */ AnsiStringType),\n/* harmony export */   \"BufferType\": () => (/* binding */ BufferType),\n/* harmony export */   \"Float16_BE\": () => (/* binding */ Float16_BE),\n/* harmony export */   \"Float16_LE\": () => (/* binding */ Float16_LE),\n/* harmony export */   \"Float32_BE\": () => (/* binding */ Float32_BE),\n/* harmony export */   \"Float32_LE\": () => (/* binding */ Float32_LE),\n/* harmony export */   \"Float64_BE\": () => (/* binding */ Float64_BE),\n/* harmony export */   \"Float64_LE\": () => (/* binding */ Float64_LE),\n/* harmony export */   \"Float80_BE\": () => (/* binding */ Float80_BE),\n/* harmony export */   \"Float80_LE\": () => (/* binding */ Float80_LE),\n/* harmony export */   \"INT16_BE\": () => (/* binding */ INT16_BE),\n/* harmony export */   \"INT16_LE\": () => (/* binding */ INT16_LE),\n/* harmony export */   \"INT24_BE\": () => (/* binding */ INT24_BE),\n/* harmony export */   \"INT24_LE\": () => (/* binding */ INT24_LE),\n/* harmony export */   \"INT32_BE\": () => (/* binding */ INT32_BE),\n/* harmony export */   \"INT32_LE\": () => (/* binding */ INT32_LE),\n/* harmony export */   \"INT64_BE\": () => (/* binding */ INT64_BE),\n/* harmony export */   \"INT64_LE\": () => (/* binding */ INT64_LE),\n/* harmony export */   \"INT8\": () => (/* binding */ INT8),\n/* harmony export */   \"IgnoreType\": () => (/* binding */ IgnoreType),\n/* harmony export */   \"StringType\": () => (/* binding */ StringType),\n/* harmony export */   \"UINT16_BE\": () => (/* binding */ UINT16_BE),\n/* harmony export */   \"UINT16_LE\": () => (/* binding */ UINT16_LE),\n/* harmony export */   \"UINT24_BE\": () => (/* binding */ UINT24_BE),\n/* harmony export */   \"UINT24_LE\": () => (/* binding */ UINT24_LE),\n/* harmony export */   \"UINT32_BE\": () => (/* binding */ UINT32_BE),\n/* harmony export */   \"UINT32_LE\": () => (/* binding */ UINT32_LE),\n/* harmony export */   \"UINT64_BE\": () => (/* binding */ UINT64_BE),\n/* harmony export */   \"UINT64_LE\": () => (/* binding */ UINT64_LE),\n/* harmony export */   \"UINT8\": () => (/* binding */ UINT8),\n/* harmony export */   \"Uint8ArrayType\": () => (/* binding */ Uint8ArrayType)\n/* harmony export */ });\n/* harmony import */ var ieee754__WEBPACK_IMPORTED_MODULE_0__ = __webpack_require__(/*! ieee754 */ \"./node_modules/ieee754/index.js\");\n/* harmony import */ var node_buffer__WEBPACK_IMPORTED_MODULE_1__ = __webpack_require__(/*! node:buffer */ \"node:buffer\");\n\n\n// Primitive types\nfunction dv(array) {\n    return new DataView(array.buffer, array.byteOffset);\n}\n/**\n * 8-bit unsigned integer\n */\nconst UINT8 = {\n    len: 1,\n    get(array, offset) {\n        return dv(array).getUint8(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint8(offset, value);\n        return offset + 1;\n    }\n};\n/**\n * 16-bit unsigned integer, Little Endian byte order\n */\nconst UINT16_LE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getUint16(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setUint16(offset, value, true);\n        return offset + 2;\n    }\n};\n/**\n * 16-bit unsigned integer, Big Endian byte order\n */\nconst UINT16_BE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getUint16(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint16(offset, value);\n        return offset + 2;\n    }\n};\n/**\n * 24-bit unsigned integer, Little Endian byte order\n */\nconst UINT24_LE = {\n    len: 3,\n    get(array, offset) {\n        const dataView = dv(array);\n        return dataView.getUint8(offset) + (dataView.getUint16(offset + 1, true) << 8);\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint8(offset, value & 0xff);\n        dataView.setUint16(offset + 1, value >> 8, true);\n        return offset + 3;\n    }\n};\n/**\n * 24-bit unsigned integer, Big Endian byte order\n */\nconst UINT24_BE = {\n    len: 3,\n    get(array, offset) {\n        const dataView = dv(array);\n        return (dataView.getUint16(offset) << 8) + dataView.getUint8(offset + 2);\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint16(offset, value >> 8);\n        dataView.setUint8(offset + 2, value & 0xff);\n        return offset + 3;\n    }\n};\n/**\n * 32-bit unsigned integer, Little Endian byte order\n */\nconst UINT32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getUint32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setUint32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * 32-bit unsigned integer, Big Endian byte order\n */\nconst UINT32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getUint32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setUint32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * 8-bit signed integer\n */\nconst INT8 = {\n    len: 1,\n    get(array, offset) {\n        return dv(array).getInt8(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt8(offset, value);\n        return offset + 1;\n    }\n};\n/**\n * 16-bit signed integer, Big Endian byte order\n */\nconst INT16_BE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getInt16(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt16(offset, value);\n        return offset + 2;\n    }\n};\n/**\n * 16-bit signed integer, Little Endian byte order\n */\nconst INT16_LE = {\n    len: 2,\n    get(array, offset) {\n        return dv(array).getInt16(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setInt16(offset, value, true);\n        return offset + 2;\n    }\n};\n/**\n * 24-bit signed integer, Little Endian byte order\n */\nconst INT24_LE = {\n    len: 3,\n    get(array, offset) {\n        const unsigned = UINT24_LE.get(array, offset);\n        return unsigned > 0x7fffff ? unsigned - 0x1000000 : unsigned;\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint8(offset, value & 0xff);\n        dataView.setUint16(offset + 1, value >> 8, true);\n        return offset + 3;\n    }\n};\n/**\n * 24-bit signed integer, Big Endian byte order\n */\nconst INT24_BE = {\n    len: 3,\n    get(array, offset) {\n        const unsigned = UINT24_BE.get(array, offset);\n        return unsigned > 0x7fffff ? unsigned - 0x1000000 : unsigned;\n    },\n    put(array, offset, value) {\n        const dataView = dv(array);\n        dataView.setUint16(offset, value >> 8);\n        dataView.setUint8(offset + 2, value & 0xff);\n        return offset + 3;\n    }\n};\n/**\n * 32-bit signed integer, Big Endian byte order\n */\nconst INT32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getInt32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setInt32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * 32-bit signed integer, Big Endian byte order\n */\nconst INT32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getInt32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setInt32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * 64-bit unsigned integer, Little Endian byte order\n */\nconst UINT64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigUint64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setBigUint64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit signed integer, Little Endian byte order\n */\nconst INT64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigInt64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setBigInt64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit unsigned integer, Big Endian byte order\n */\nconst UINT64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigUint64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setBigUint64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * 64-bit signed integer, Big Endian byte order\n */\nconst INT64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getBigInt64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setBigInt64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 16-bit (half precision) float, big endian\n */\nconst Float16_BE = {\n    len: 2,\n    get(dataView, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(dataView, offset, false, 10, this.len);\n    },\n    put(dataView, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(dataView, value, offset, false, 10, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 16-bit (half precision) float, little endian\n */\nconst Float16_LE = {\n    len: 2,\n    get(array, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(array, offset, true, 10, this.len);\n    },\n    put(array, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(array, value, offset, true, 10, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 32-bit (single precision) float, big endian\n */\nconst Float32_BE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getFloat32(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat32(offset, value);\n        return offset + 4;\n    }\n};\n/**\n * IEEE 754 32-bit (single precision) float, little endian\n */\nconst Float32_LE = {\n    len: 4,\n    get(array, offset) {\n        return dv(array).getFloat32(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat32(offset, value, true);\n        return offset + 4;\n    }\n};\n/**\n * IEEE 754 64-bit (double precision) float, big endian\n */\nconst Float64_BE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getFloat64(offset);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat64(offset, value);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 64-bit (double precision) float, little endian\n */\nconst Float64_LE = {\n    len: 8,\n    get(array, offset) {\n        return dv(array).getFloat64(offset, true);\n    },\n    put(array, offset, value) {\n        dv(array).setFloat64(offset, value, true);\n        return offset + 8;\n    }\n};\n/**\n * IEEE 754 80-bit (extended precision) float, big endian\n */\nconst Float80_BE = {\n    len: 10,\n    get(array, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(array, offset, false, 63, this.len);\n    },\n    put(array, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(array, value, offset, false, 63, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * IEEE 754 80-bit (extended precision) float, little endian\n */\nconst Float80_LE = {\n    len: 10,\n    get(array, offset) {\n        return ieee754__WEBPACK_IMPORTED_MODULE_0__.read(array, offset, true, 63, this.len);\n    },\n    put(array, offset, value) {\n        ieee754__WEBPACK_IMPORTED_MODULE_0__.write(array, value, offset, true, 63, this.len);\n        return offset + this.len;\n    }\n};\n/**\n * Ignore a given number of bytes\n */\nclass IgnoreType {\n    /**\n     * @param len number of bytes to ignore\n     */\n    constructor(len) {\n        this.len = len;\n    }\n    // ToDo: don't read, but skip data\n    // eslint-disable-next-line @typescript-eslint/no-empty-function\n    get(array, off) {\n    }\n}\nclass Uint8ArrayType {\n    constructor(len) {\n        this.len = len;\n    }\n    get(array, offset) {\n        return array.subarray(offset, offset + this.len);\n    }\n}\nclass BufferType {\n    constructor(len) {\n        this.len = len;\n    }\n    get(uint8Array, off) {\n        return node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.from(uint8Array.subarray(off, off + this.len));\n    }\n}\n/**\n * Consume a fixed number of bytes from the stream and return a string with a specified encoding.\n */\nclass StringType {\n    constructor(len, encoding) {\n        this.len = len;\n        this.encoding = encoding;\n    }\n    get(uint8Array, offset) {\n        return node_buffer__WEBPACK_IMPORTED_MODULE_1__.Buffer.from(uint8Array).toString(this.encoding, offset, offset + this.len);\n    }\n}\n/**\n * ANSI Latin 1 String\n * Using windows-1252 / ISO 8859-1 decoding\n */\nclass AnsiStringType {\n    constructor(len) {\n        this.len = len;\n    }\n    static decode(buffer, offset, until) {\n        let str = '';\n        for (let i = offset; i < until; ++i) {\n            str += AnsiStringType.codePointToString(AnsiStringType.singleByteDecoder(buffer[i]));\n        }\n        return str;\n    }\n    static inRange(a, min, max) {\n        return min <= a && a <= max;\n    }\n    static codePointToString(cp) {\n        if (cp <= 0xFFFF) {\n            return String.fromCharCode(cp);\n        }\n        else {\n            cp -= 0x10000;\n            return String.fromCharCode((cp >> 10) + 0xD800, (cp & 0x3FF) + 0xDC00);\n        }\n    }\n    static singleByteDecoder(bite) {\n        if (AnsiStringType.inRange(bite, 0x00, 0x7F)) {\n            return bite;\n        }\n        const codePoint = AnsiStringType.windows1252[bite - 0x80];\n        if (codePoint === null) {\n            throw Error('invaliding encoding');\n        }\n        return codePoint;\n    }\n    get(buffer, offset = 0) {\n        return AnsiStringType.decode(buffer, offset, offset + this.len);\n    }\n}\nAnsiStringType.windows1252 = [8364, 129, 8218, 402, 8222, 8230, 8224, 8225, 710, 8240, 352,\n    8249, 338, 141, 381, 143, 144, 8216, 8217, 8220, 8221, 8226, 8211, 8212, 732,\n    8482, 353, 8250, 339, 157, 382, 376, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n    169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184,\n    185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200,\n    201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216,\n    217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232,\n    233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247,\n    248, 249, 250, 251, 252, 253, 254, 255];\n\n\n//# sourceURL=webpack://discord-bot/./node_modules/token-types/lib/index.js?");

/***/ })

}]);